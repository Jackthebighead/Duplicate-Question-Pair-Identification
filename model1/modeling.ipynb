{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training for `Quora Question pair similarity`\n",
    "\n",
    "For **2nd iteration**. Use Featured data (generated from `feature_engineering_test` and `feature_engineering_train`) for Model Training\n",
    "\n",
    "- Get the featured train and test data from corresponding files\n",
    "- Put train and test data into modeling\n",
    "- Get results and submissions\n",
    "- Input: \n",
    "  - vectors feature from `final_features.csv` as well as test_data version (because en_core_web_md will run out of memory in my laptop, so i use the vector features from en_core_web_sm that i saved before)\n",
    "  - `feature_tm.csv` as well as test_data version (contains train.csv)\n",
    "  - `feature_nlp.csv` as well as test_data version\n",
    "- Ouput: models in `Models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training features from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.591466</td>\n",
       "      <td>96.113849</td>\n",
       "      <td>31.001480</td>\n",
       "      <td>-44.172052</td>\n",
       "      <td>21.397091</td>\n",
       "      <td>-46.908810</td>\n",
       "      <td>-100.162247</td>\n",
       "      <td>-1.978221</td>\n",
       "      <td>38.112752</td>\n",
       "      <td>-11.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.838611</td>\n",
       "      <td>54.099417</td>\n",
       "      <td>-65.543286</td>\n",
       "      <td>-23.634332</td>\n",
       "      <td>-85.303453</td>\n",
       "      <td>33.143694</td>\n",
       "      <td>-65.774337</td>\n",
       "      <td>28.145018</td>\n",
       "      <td>-22.243213</td>\n",
       "      <td>0.169092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.926253</td>\n",
       "      <td>33.117176</td>\n",
       "      <td>66.706154</td>\n",
       "      <td>50.397498</td>\n",
       "      <td>42.266215</td>\n",
       "      <td>-29.920099</td>\n",
       "      <td>-53.378103</td>\n",
       "      <td>-31.755547</td>\n",
       "      <td>77.061497</td>\n",
       "      <td>9.438696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.491278</td>\n",
       "      <td>44.788221</td>\n",
       "      <td>6.437781</td>\n",
       "      <td>39.981581</td>\n",
       "      <td>-43.237003</td>\n",
       "      <td>39.471643</td>\n",
       "      <td>-0.322382</td>\n",
       "      <td>-6.074735</td>\n",
       "      <td>-4.417220</td>\n",
       "      <td>5.627428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.084751</td>\n",
       "      <td>37.174410</td>\n",
       "      <td>0.356843</td>\n",
       "      <td>-29.468567</td>\n",
       "      <td>33.367771</td>\n",
       "      <td>-12.860933</td>\n",
       "      <td>-44.425541</td>\n",
       "      <td>3.958389</td>\n",
       "      <td>-13.291972</td>\n",
       "      <td>-9.029029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max  \\\n",
       "0           0   0             0  0.999980  0.833319  0.999983  0.999983   \n",
       "1           1   1             0  0.799984  0.399996  0.749981  0.599988   \n",
       "2           2   2             0  0.399992  0.333328  0.399992  0.249997   \n",
       "3           3   3             0  0.000000  0.000000  0.000000  0.000000   \n",
       "4           4   4             0  0.399992  0.199998  0.999950  0.666644   \n",
       "\n",
       "    ctc_min   ctc_max  last_word_eq  ...       86_y       87_y       88_y  \\\n",
       "0  0.916659  0.785709           0.0  ...  15.591466  96.113849  31.001480   \n",
       "1  0.699993  0.466664           0.0  ... -84.838611  54.099417 -65.543286   \n",
       "2  0.399996  0.285712           0.0  ...  27.926253  33.117176  66.706154   \n",
       "3  0.000000  0.000000           0.0  ...  -7.491278  44.788221   6.437781   \n",
       "4  0.571420  0.307690           0.0  ...  44.084751  37.174410   0.356843   \n",
       "\n",
       "        89_y       90_y       91_y        92_y       93_y       94_y  \\\n",
       "0 -44.172052  21.397091 -46.908810 -100.162247  -1.978221  38.112752   \n",
       "1 -23.634332 -85.303453  33.143694  -65.774337  28.145018 -22.243213   \n",
       "2  50.397498  42.266215 -29.920099  -53.378103 -31.755547  77.061497   \n",
       "3  39.981581 -43.237003  39.471643   -0.322382  -6.074735  -4.417220   \n",
       "4 -29.468567  33.367771 -12.860933  -44.425541   3.958389 -13.291972   \n",
       "\n",
       "        95_y  \n",
       "0 -11.592531  \n",
       "1   0.169092  \n",
       "2   9.438696  \n",
       "3   5.627428  \n",
       "4  -9.029029  \n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vector features from final_features.csv (becasue it is the same (all used spacy_en_core_web_sm))\n",
    "\n",
    "data_csv = pd.read_csv('final_features.csv')\n",
    "data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get training labels \n",
    "\n",
    "y_true = data_csv['is_duplicate']\n",
    "len(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the columns to be dropped ['Unnamed: 0', 'is_duplicate', 'cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq', 'first_word_eq', 'abs_len_diff', 'mean_len', 'token_set_ratio', 'token_sort_ratio', 'fuzz_ratio', 'fuzz_partial_ratio', 'longest_substr_ratio', 'freq_qid1', 'freq_qid2', 'q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_Common', 'word_Total', 'word_share', 'freq_q1+q2', 'freq_q1-q2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.682992</td>\n",
       "      <td>87.635912</td>\n",
       "      <td>77.898819</td>\n",
       "      <td>-61.473692</td>\n",
       "      <td>44.053226</td>\n",
       "      <td>18.525178</td>\n",
       "      <td>-28.609312</td>\n",
       "      <td>47.452460</td>\n",
       "      <td>-86.095610</td>\n",
       "      <td>...</td>\n",
       "      <td>15.591466</td>\n",
       "      <td>96.113849</td>\n",
       "      <td>31.001480</td>\n",
       "      <td>-44.172052</td>\n",
       "      <td>21.397091</td>\n",
       "      <td>-46.908810</td>\n",
       "      <td>-100.162247</td>\n",
       "      <td>-1.978221</td>\n",
       "      <td>38.112752</td>\n",
       "      <td>-11.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.993008</td>\n",
       "      <td>55.174564</td>\n",
       "      <td>-2.049167</td>\n",
       "      <td>36.677249</td>\n",
       "      <td>85.412371</td>\n",
       "      <td>-45.989080</td>\n",
       "      <td>31.112590</td>\n",
       "      <td>76.453094</td>\n",
       "      <td>-74.456509</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.838611</td>\n",
       "      <td>54.099417</td>\n",
       "      <td>-65.543286</td>\n",
       "      <td>-23.634332</td>\n",
       "      <td>-85.303453</td>\n",
       "      <td>33.143694</td>\n",
       "      <td>-65.774337</td>\n",
       "      <td>28.145018</td>\n",
       "      <td>-22.243213</td>\n",
       "      <td>0.169092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62.709638</td>\n",
       "      <td>72.489519</td>\n",
       "      <td>10.889310</td>\n",
       "      <td>-45.772860</td>\n",
       "      <td>71.261772</td>\n",
       "      <td>-34.385969</td>\n",
       "      <td>-26.228285</td>\n",
       "      <td>18.224490</td>\n",
       "      <td>-113.496336</td>\n",
       "      <td>...</td>\n",
       "      <td>27.926253</td>\n",
       "      <td>33.117176</td>\n",
       "      <td>66.706154</td>\n",
       "      <td>50.397498</td>\n",
       "      <td>42.266215</td>\n",
       "      <td>-29.920099</td>\n",
       "      <td>-53.378103</td>\n",
       "      <td>-31.755547</td>\n",
       "      <td>77.061497</td>\n",
       "      <td>9.438696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>35.006791</td>\n",
       "      <td>-40.413219</td>\n",
       "      <td>53.450493</td>\n",
       "      <td>-45.069038</td>\n",
       "      <td>37.137247</td>\n",
       "      <td>-21.992808</td>\n",
       "      <td>-28.184323</td>\n",
       "      <td>131.916699</td>\n",
       "      <td>41.891510</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.491278</td>\n",
       "      <td>44.788221</td>\n",
       "      <td>6.437781</td>\n",
       "      <td>39.981581</td>\n",
       "      <td>-43.237003</td>\n",
       "      <td>39.471643</td>\n",
       "      <td>-0.322382</td>\n",
       "      <td>-6.074735</td>\n",
       "      <td>-4.417220</td>\n",
       "      <td>5.627428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>135.425154</td>\n",
       "      <td>187.445625</td>\n",
       "      <td>143.612776</td>\n",
       "      <td>-111.735024</td>\n",
       "      <td>56.977977</td>\n",
       "      <td>-70.101866</td>\n",
       "      <td>-47.585533</td>\n",
       "      <td>59.575895</td>\n",
       "      <td>-56.992457</td>\n",
       "      <td>...</td>\n",
       "      <td>44.084751</td>\n",
       "      <td>37.174410</td>\n",
       "      <td>0.356843</td>\n",
       "      <td>-29.468567</td>\n",
       "      <td>33.367771</td>\n",
       "      <td>-12.860933</td>\n",
       "      <td>-44.425541</td>\n",
       "      <td>3.958389</td>\n",
       "      <td>-13.291972</td>\n",
       "      <td>-9.029029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404285</td>\n",
       "      <td>404285</td>\n",
       "      <td>59.267353</td>\n",
       "      <td>53.308570</td>\n",
       "      <td>59.214630</td>\n",
       "      <td>-41.510235</td>\n",
       "      <td>134.183171</td>\n",
       "      <td>-44.156874</td>\n",
       "      <td>-158.025249</td>\n",
       "      <td>35.570810</td>\n",
       "      <td>-76.939342</td>\n",
       "      <td>...</td>\n",
       "      <td>39.309001</td>\n",
       "      <td>15.758037</td>\n",
       "      <td>36.746870</td>\n",
       "      <td>-57.793078</td>\n",
       "      <td>75.146161</td>\n",
       "      <td>-20.305723</td>\n",
       "      <td>-19.072270</td>\n",
       "      <td>-2.160282</td>\n",
       "      <td>105.635542</td>\n",
       "      <td>-16.815833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404286</td>\n",
       "      <td>404286</td>\n",
       "      <td>-22.483616</td>\n",
       "      <td>15.514055</td>\n",
       "      <td>44.191165</td>\n",
       "      <td>-43.024130</td>\n",
       "      <td>33.000220</td>\n",
       "      <td>48.886315</td>\n",
       "      <td>-33.129761</td>\n",
       "      <td>-27.532968</td>\n",
       "      <td>-22.914073</td>\n",
       "      <td>...</td>\n",
       "      <td>6.886801</td>\n",
       "      <td>30.711425</td>\n",
       "      <td>-32.673037</td>\n",
       "      <td>28.673688</td>\n",
       "      <td>82.408519</td>\n",
       "      <td>-10.283080</td>\n",
       "      <td>46.515741</td>\n",
       "      <td>-55.934617</td>\n",
       "      <td>8.210074</td>\n",
       "      <td>-22.594306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404287</td>\n",
       "      <td>404287</td>\n",
       "      <td>8.086156</td>\n",
       "      <td>13.003350</td>\n",
       "      <td>1.550075</td>\n",
       "      <td>-37.361558</td>\n",
       "      <td>-6.396335</td>\n",
       "      <td>-9.639999</td>\n",
       "      <td>21.519365</td>\n",
       "      <td>-3.257762</td>\n",
       "      <td>-17.741784</td>\n",
       "      <td>...</td>\n",
       "      <td>5.319683</td>\n",
       "      <td>20.635684</td>\n",
       "      <td>-8.970818</td>\n",
       "      <td>3.478943</td>\n",
       "      <td>17.787663</td>\n",
       "      <td>-7.907412</td>\n",
       "      <td>-10.202242</td>\n",
       "      <td>-34.997149</td>\n",
       "      <td>15.290493</td>\n",
       "      <td>5.483173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404288</td>\n",
       "      <td>404288</td>\n",
       "      <td>98.757430</td>\n",
       "      <td>34.897575</td>\n",
       "      <td>15.768073</td>\n",
       "      <td>-149.475133</td>\n",
       "      <td>82.196690</td>\n",
       "      <td>-83.929605</td>\n",
       "      <td>-80.157925</td>\n",
       "      <td>11.396484</td>\n",
       "      <td>-116.004433</td>\n",
       "      <td>...</td>\n",
       "      <td>45.423385</td>\n",
       "      <td>94.190066</td>\n",
       "      <td>64.764972</td>\n",
       "      <td>-76.355071</td>\n",
       "      <td>-26.776399</td>\n",
       "      <td>29.434206</td>\n",
       "      <td>-67.713252</td>\n",
       "      <td>4.832993</td>\n",
       "      <td>-63.650805</td>\n",
       "      <td>-5.479479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404289</td>\n",
       "      <td>404289</td>\n",
       "      <td>27.115249</td>\n",
       "      <td>40.931406</td>\n",
       "      <td>-2.850099</td>\n",
       "      <td>-18.375519</td>\n",
       "      <td>0.609458</td>\n",
       "      <td>-12.867771</td>\n",
       "      <td>20.039677</td>\n",
       "      <td>32.806808</td>\n",
       "      <td>-17.191067</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.524191</td>\n",
       "      <td>28.663685</td>\n",
       "      <td>-18.173738</td>\n",
       "      <td>34.936834</td>\n",
       "      <td>-11.322893</td>\n",
       "      <td>-10.891564</td>\n",
       "      <td>-7.098439</td>\n",
       "      <td>-64.827279</td>\n",
       "      <td>-4.088562</td>\n",
       "      <td>-31.983831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         0_x         1_x         2_x         3_x         4_x  \\\n",
       "0            0   78.682992   87.635912   77.898819  -61.473692   44.053226   \n",
       "1            1   99.993008   55.174564   -2.049167   36.677249   85.412371   \n",
       "2            2   62.709638   72.489519   10.889310  -45.772860   71.261772   \n",
       "3            3   35.006791  -40.413219   53.450493  -45.069038   37.137247   \n",
       "4            4  135.425154  187.445625  143.612776 -111.735024   56.977977   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "404285  404285   59.267353   53.308570   59.214630  -41.510235  134.183171   \n",
       "404286  404286  -22.483616   15.514055   44.191165  -43.024130   33.000220   \n",
       "404287  404287    8.086156   13.003350    1.550075  -37.361558   -6.396335   \n",
       "404288  404288   98.757430   34.897575   15.768073 -149.475133   82.196690   \n",
       "404289  404289   27.115249   40.931406   -2.850099  -18.375519    0.609458   \n",
       "\n",
       "              5_x         6_x         7_x         8_x  ...       86_y  \\\n",
       "0       18.525178  -28.609312   47.452460  -86.095610  ...  15.591466   \n",
       "1      -45.989080   31.112590   76.453094  -74.456509  ... -84.838611   \n",
       "2      -34.385969  -26.228285   18.224490 -113.496336  ...  27.926253   \n",
       "3      -21.992808  -28.184323  131.916699   41.891510  ...  -7.491278   \n",
       "4      -70.101866  -47.585533   59.575895  -56.992457  ...  44.084751   \n",
       "...           ...         ...         ...         ...  ...        ...   \n",
       "404285 -44.156874 -158.025249   35.570810  -76.939342  ...  39.309001   \n",
       "404286  48.886315  -33.129761  -27.532968  -22.914073  ...   6.886801   \n",
       "404287  -9.639999   21.519365   -3.257762  -17.741784  ...   5.319683   \n",
       "404288 -83.929605  -80.157925   11.396484 -116.004433  ...  45.423385   \n",
       "404289 -12.867771   20.039677   32.806808  -17.191067  ... -15.524191   \n",
       "\n",
       "             87_y       88_y       89_y       90_y       91_y        92_y  \\\n",
       "0       96.113849  31.001480 -44.172052  21.397091 -46.908810 -100.162247   \n",
       "1       54.099417 -65.543286 -23.634332 -85.303453  33.143694  -65.774337   \n",
       "2       33.117176  66.706154  50.397498  42.266215 -29.920099  -53.378103   \n",
       "3       44.788221   6.437781  39.981581 -43.237003  39.471643   -0.322382   \n",
       "4       37.174410   0.356843 -29.468567  33.367771 -12.860933  -44.425541   \n",
       "...           ...        ...        ...        ...        ...         ...   \n",
       "404285  15.758037  36.746870 -57.793078  75.146161 -20.305723  -19.072270   \n",
       "404286  30.711425 -32.673037  28.673688  82.408519 -10.283080   46.515741   \n",
       "404287  20.635684  -8.970818   3.478943  17.787663  -7.907412  -10.202242   \n",
       "404288  94.190066  64.764972 -76.355071 -26.776399  29.434206  -67.713252   \n",
       "404289  28.663685 -18.173738  34.936834 -11.322893 -10.891564   -7.098439   \n",
       "\n",
       "             93_y        94_y       95_y  \n",
       "0       -1.978221   38.112752 -11.592531  \n",
       "1       28.145018  -22.243213   0.169092  \n",
       "2      -31.755547   77.061497   9.438696  \n",
       "3       -6.074735   -4.417220   5.627428  \n",
       "4        3.958389  -13.291972  -9.029029  \n",
       "...           ...         ...        ...  \n",
       "404285  -2.160282  105.635542 -16.815833  \n",
       "404286 -55.934617    8.210074 -22.594306  \n",
       "404287 -34.997149   15.290493   5.483173  \n",
       "404288   4.832993  -63.650805  -5.479479  \n",
       "404289 -64.827279   -4.088562 -31.983831  \n",
       "\n",
       "[404290 rows x 193 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unecessary columns\n",
    "\n",
    "columns_drop = []\n",
    "columns_drop.append(data_csv.columns[0])\n",
    "columns_drop += data_csv.columns[2:29].tolist()\n",
    "print(\"These are the columns to be dropped\", columns_drop)\n",
    "\n",
    "df_vectors = data_csv.drop(columns=columns_drop,axis=1)\n",
    "df_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features from features_tm.csv and features_nlp.csv\n",
    "\n",
    "df_tm = pd.read_csv('Features/feature_tm.csv')\n",
    "df_nlp = pd.read_csv('Features/feature_nlp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>diff_len_char</th>\n",
       "      <th>avg_world_len1</th>\n",
       "      <th>avg_world_len2</th>\n",
       "      <th>diff_avg_word</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>share_2_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>-37</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>76</td>\n",
       "      <td>-32</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.846154</td>\n",
       "      <td>-0.346154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>-15</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "      <td>-17</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>-2.696970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404285</td>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>5.153846</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404286</td>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404287</td>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404288</td>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>127</td>\n",
       "      <td>-33</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>103</td>\n",
       "      <td>-25</td>\n",
       "      <td>4.588235</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>0.468235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404289</td>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-6</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "0       What is the step by step guide to invest in sh...             0   \n",
       "1       What would happen if the Indian government sto...             0   \n",
       "2       How can Internet speed be increased by hacking...             0   \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4                 Which fish would survive in salt water?             0   \n",
       "...                                                   ...           ...   \n",
       "404285  How many keywords are there in PERL Programmin...             0   \n",
       "404286         Is it true that there is life after death?             1   \n",
       "404287                                  What's this coin?             0   \n",
       "404288  I am having little hairfall problem but I want...             0   \n",
       "404289      What is it like to have sex with your cousin?             0   \n",
       "\n",
       "        q1len  q2len  diff_len  len_word_q1  ...  len_char_q1  len_char_q2  \\\n",
       "0          66     57         9           14  ...           53           46   \n",
       "1          51     88       -37            8  ...           44           76   \n",
       "2          73     59        14           14  ...           60           50   \n",
       "3          50     65       -15           11  ...           40           57   \n",
       "4          76     39        37           13  ...           64           33   \n",
       "...       ...    ...       ...          ...  ...          ...          ...   \n",
       "404285     85     79         6           14  ...           72           67   \n",
       "404286     41     42        -1            8  ...           34           34   \n",
       "404287     17     17         0            4  ...           14           15   \n",
       "404288     94    127       -33           17  ...           78          103   \n",
       "404289     37     45        -8            8  ...           30           36   \n",
       "\n",
       "        diff_len_char  avg_world_len1  avg_world_len2  diff_avg_word  \\\n",
       "0                   7        3.785714        3.833333      -0.047619   \n",
       "1                 -32        5.500000        5.846154      -0.346154   \n",
       "2                  10        4.285714        5.000000      -0.714286   \n",
       "3                 -17        3.636364        6.333333      -2.696970   \n",
       "4                  31        4.923077        4.714286       0.208791   \n",
       "...               ...             ...             ...            ...   \n",
       "404285              5        5.142857        5.153846      -0.010989   \n",
       "404286              0        4.250000        3.777778       0.472222   \n",
       "404287             -1        3.500000        5.000000      -1.500000   \n",
       "404288            -25        4.588235        4.120000       0.468235   \n",
       "404289             -6        3.750000        3.600000       0.150000   \n",
       "\n",
       "        word_Common  word_Total  word_share  share_2_gram  \n",
       "0              10.0        23.0    0.434783      0.416667  \n",
       "1               4.0        20.0    0.200000      0.052632  \n",
       "2               4.0        24.0    0.166667      0.045455  \n",
       "3               0.0        19.0    0.000000      0.000000  \n",
       "4               2.0        20.0    0.100000      0.000000  \n",
       "...             ...         ...         ...           ...  \n",
       "404285         11.0        25.0    0.440000      0.360000  \n",
       "404286          5.0        16.0    0.312500      0.266667  \n",
       "404287          1.0         7.0    0.142857      0.000000  \n",
       "404288          1.0        40.0    0.025000      0.000000  \n",
       "404289          8.0        18.0    0.444444      0.312500  \n",
       "\n",
       "[404290 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>word_mover_dist</th>\n",
       "      <th>cosine_dist</th>\n",
       "      <th>cityblock_dist</th>\n",
       "      <th>canberra_dist</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>minkowski_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.216034</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>14.274065</td>\n",
       "      <td>91.483062</td>\n",
       "      <td>1.047253</td>\n",
       "      <td>1.047253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>4.897662</td>\n",
       "      <td>0.266555</td>\n",
       "      <td>33.272633</td>\n",
       "      <td>149.670092</td>\n",
       "      <td>2.624989</td>\n",
       "      <td>2.624989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.011556</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>28.457512</td>\n",
       "      <td>129.214660</td>\n",
       "      <td>2.140298</td>\n",
       "      <td>2.140298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>7.514702</td>\n",
       "      <td>0.619671</td>\n",
       "      <td>62.016426</td>\n",
       "      <td>200.899534</td>\n",
       "      <td>4.702347</td>\n",
       "      <td>4.702347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>6.257260</td>\n",
       "      <td>0.244168</td>\n",
       "      <td>40.127296</td>\n",
       "      <td>156.627744</td>\n",
       "      <td>3.145122</td>\n",
       "      <td>3.145122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404285</td>\n",
       "      <td>404285</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.846147</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>1.351202</td>\n",
       "      <td>0.061603</td>\n",
       "      <td>18.532461</td>\n",
       "      <td>110.665066</td>\n",
       "      <td>1.351204</td>\n",
       "      <td>1.351204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404286</td>\n",
       "      <td>404286</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.555549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.518507</td>\n",
       "      <td>0.047257</td>\n",
       "      <td>20.919132</td>\n",
       "      <td>104.808199</td>\n",
       "      <td>1.518508</td>\n",
       "      <td>1.518508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404287</td>\n",
       "      <td>404287</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>3.399536</td>\n",
       "      <td>0.114690</td>\n",
       "      <td>45.974075</td>\n",
       "      <td>124.490252</td>\n",
       "      <td>3.399536</td>\n",
       "      <td>3.399536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404288</td>\n",
       "      <td>404288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>0.099999</td>\n",
       "      <td>0.058823</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>8.156665</td>\n",
       "      <td>0.569064</td>\n",
       "      <td>50.616547</td>\n",
       "      <td>219.051497</td>\n",
       "      <td>3.740317</td>\n",
       "      <td>3.740317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404289</td>\n",
       "      <td>404289</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.799992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n",
       "0            0  0.999980  0.833319  0.999983  0.999983  0.916659  0.785709   \n",
       "1            1  0.799984  0.399996  0.749981  0.599988  0.699993  0.466664   \n",
       "2            2  0.399992  0.333328  0.399992  0.249997  0.399996  0.285712   \n",
       "3            3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4            4  0.399992  0.199998  0.999950  0.666644  0.571420  0.307690   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "404285  404285  0.857131  0.857131  0.999980  0.833319  0.846147  0.785709   \n",
       "404286  404286  0.666644  0.666644  0.599988  0.599988  0.624992  0.555549   \n",
       "404287  404287  0.999900  0.499975  0.999950  0.666644  0.749981  0.749981   \n",
       "404288  404288  0.000000  0.000000  0.124998  0.099999  0.058823  0.040000   \n",
       "404289  404289  0.999967  0.999967  0.999980  0.714276  0.999988  0.799992   \n",
       "\n",
       "        last_word_eq  first_word_eq  abs_len_diff  ...  token_sort_ratio  \\\n",
       "0                0.0            1.0           2.0  ...                93   \n",
       "1                0.0            1.0           5.0  ...                63   \n",
       "2                0.0            1.0           4.0  ...                63   \n",
       "3                0.0            0.0           2.0  ...                24   \n",
       "4                0.0            1.0           6.0  ...                47   \n",
       "...              ...            ...           ...  ...               ...   \n",
       "404285           1.0            1.0           1.0  ...                88   \n",
       "404286           1.0            0.0           1.0  ...                69   \n",
       "404287           1.0            1.0           0.0  ...                79   \n",
       "404288           0.0            0.0           8.0  ...                35   \n",
       "404289           1.0            1.0           2.0  ...                90   \n",
       "\n",
       "        fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  word_mover_dist  \\\n",
       "0               93                 100              0.982759         1.216034   \n",
       "1               66                  75              0.596154         4.897662   \n",
       "2               43                  47              0.166667         4.011556   \n",
       "3                9                  14              0.039216         7.514702   \n",
       "4               35                  56              0.175000         6.257260   \n",
       "...            ...                 ...                   ...              ...   \n",
       "404285          91                  87              0.387500         1.351202   \n",
       "404286          72                  76              0.642857         1.518507   \n",
       "404287          79                  76              0.444444         3.399536   \n",
       "404288          30                  34              0.052632         8.156665   \n",
       "404289          90                  86              0.605263         0.000000   \n",
       "\n",
       "        cosine_dist  cityblock_dist  canberra_dist  euclidean_dist  \\\n",
       "0          0.031762       14.274065      91.483062        1.047253   \n",
       "1          0.266555       33.272633     149.670092        2.624989   \n",
       "2          0.118900       28.457512     129.214660        2.140298   \n",
       "3          0.619671       62.016426     200.899534        4.702347   \n",
       "4          0.244168       40.127296     156.627744        3.145122   \n",
       "...             ...             ...            ...             ...   \n",
       "404285     0.061603       18.532461     110.665066        1.351204   \n",
       "404286     0.047257       20.919132     104.808199        1.518508   \n",
       "404287     0.114690       45.974075     124.490252        3.399536   \n",
       "404288     0.569064       50.616547     219.051497        3.740317   \n",
       "404289     0.000000        0.000000       0.000000        0.000000   \n",
       "\n",
       "        minkowski_dist  \n",
       "0             1.047253  \n",
       "1             2.624989  \n",
       "2             2.140298  \n",
       "3             4.702347  \n",
       "4             3.145122  \n",
       "...                ...  \n",
       "404285        1.351204  \n",
       "404286        1.518508  \n",
       "404287        3.399536  \n",
       "404288        3.740317  \n",
       "404289        0.000000  \n",
       "\n",
       "[404290 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>15.591466</td>\n",
       "      <td>96.113849</td>\n",
       "      <td>31.001480</td>\n",
       "      <td>-44.172052</td>\n",
       "      <td>21.397091</td>\n",
       "      <td>-46.908810</td>\n",
       "      <td>-100.162247</td>\n",
       "      <td>-1.978221</td>\n",
       "      <td>38.112752</td>\n",
       "      <td>-11.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>-37</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.838611</td>\n",
       "      <td>54.099417</td>\n",
       "      <td>-65.543286</td>\n",
       "      <td>-23.634332</td>\n",
       "      <td>-85.303453</td>\n",
       "      <td>33.143694</td>\n",
       "      <td>-65.774337</td>\n",
       "      <td>28.145018</td>\n",
       "      <td>-22.243213</td>\n",
       "      <td>0.169092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>27.926253</td>\n",
       "      <td>33.117176</td>\n",
       "      <td>66.706154</td>\n",
       "      <td>50.397498</td>\n",
       "      <td>42.266215</td>\n",
       "      <td>-29.920099</td>\n",
       "      <td>-53.378103</td>\n",
       "      <td>-31.755547</td>\n",
       "      <td>77.061497</td>\n",
       "      <td>9.438696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>-15</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.491278</td>\n",
       "      <td>44.788221</td>\n",
       "      <td>6.437781</td>\n",
       "      <td>39.981581</td>\n",
       "      <td>-43.237003</td>\n",
       "      <td>39.471643</td>\n",
       "      <td>-0.322382</td>\n",
       "      <td>-6.074735</td>\n",
       "      <td>-4.417220</td>\n",
       "      <td>5.627428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>44.084751</td>\n",
       "      <td>37.174410</td>\n",
       "      <td>0.356843</td>\n",
       "      <td>-29.468567</td>\n",
       "      <td>33.367771</td>\n",
       "      <td>-12.860933</td>\n",
       "      <td>-44.425541</td>\n",
       "      <td>3.958389</td>\n",
       "      <td>-13.291972</td>\n",
       "      <td>-9.029029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404285</td>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>39.309001</td>\n",
       "      <td>15.758037</td>\n",
       "      <td>36.746870</td>\n",
       "      <td>-57.793078</td>\n",
       "      <td>75.146161</td>\n",
       "      <td>-20.305723</td>\n",
       "      <td>-19.072270</td>\n",
       "      <td>-2.160282</td>\n",
       "      <td>105.635542</td>\n",
       "      <td>-16.815833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404286</td>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6.886801</td>\n",
       "      <td>30.711425</td>\n",
       "      <td>-32.673037</td>\n",
       "      <td>28.673688</td>\n",
       "      <td>82.408519</td>\n",
       "      <td>-10.283080</td>\n",
       "      <td>46.515741</td>\n",
       "      <td>-55.934617</td>\n",
       "      <td>8.210074</td>\n",
       "      <td>-22.594306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404287</td>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.319683</td>\n",
       "      <td>20.635684</td>\n",
       "      <td>-8.970818</td>\n",
       "      <td>3.478943</td>\n",
       "      <td>17.787663</td>\n",
       "      <td>-7.907412</td>\n",
       "      <td>-10.202242</td>\n",
       "      <td>-34.997149</td>\n",
       "      <td>15.290493</td>\n",
       "      <td>5.483173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404288</td>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>127</td>\n",
       "      <td>-33</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>45.423385</td>\n",
       "      <td>94.190066</td>\n",
       "      <td>64.764972</td>\n",
       "      <td>-76.355071</td>\n",
       "      <td>-26.776399</td>\n",
       "      <td>29.434206</td>\n",
       "      <td>-67.713252</td>\n",
       "      <td>4.832993</td>\n",
       "      <td>-63.650805</td>\n",
       "      <td>-5.479479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404289</td>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.524191</td>\n",
       "      <td>28.663685</td>\n",
       "      <td>-18.173738</td>\n",
       "      <td>34.936834</td>\n",
       "      <td>-11.322893</td>\n",
       "      <td>-10.891564</td>\n",
       "      <td>-7.098439</td>\n",
       "      <td>-64.827279</td>\n",
       "      <td>-4.088562</td>\n",
       "      <td>-31.983831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "0       What is the step by step guide to invest in sh...             0   \n",
       "1       What would happen if the Indian government sto...             0   \n",
       "2       How can Internet speed be increased by hacking...             0   \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4                 Which fish would survive in salt water?             0   \n",
       "...                                                   ...           ...   \n",
       "404285  How many keywords are there in PERL Programmin...             0   \n",
       "404286         Is it true that there is life after death?             1   \n",
       "404287                                  What's this coin?             0   \n",
       "404288  I am having little hairfall problem but I want...             0   \n",
       "404289      What is it like to have sex with your cousin?             0   \n",
       "\n",
       "        q1len  q2len  diff_len  len_word_q1  ...       86_y       87_y  \\\n",
       "0          66     57         9           14  ...  15.591466  96.113849   \n",
       "1          51     88       -37            8  ... -84.838611  54.099417   \n",
       "2          73     59        14           14  ...  27.926253  33.117176   \n",
       "3          50     65       -15           11  ...  -7.491278  44.788221   \n",
       "4          76     39        37           13  ...  44.084751  37.174410   \n",
       "...       ...    ...       ...          ...  ...        ...        ...   \n",
       "404285     85     79         6           14  ...  39.309001  15.758037   \n",
       "404286     41     42        -1            8  ...   6.886801  30.711425   \n",
       "404287     17     17         0            4  ...   5.319683  20.635684   \n",
       "404288     94    127       -33           17  ...  45.423385  94.190066   \n",
       "404289     37     45        -8            8  ... -15.524191  28.663685   \n",
       "\n",
       "             88_y       89_y       90_y       91_y        92_y       93_y  \\\n",
       "0       31.001480 -44.172052  21.397091 -46.908810 -100.162247  -1.978221   \n",
       "1      -65.543286 -23.634332 -85.303453  33.143694  -65.774337  28.145018   \n",
       "2       66.706154  50.397498  42.266215 -29.920099  -53.378103 -31.755547   \n",
       "3        6.437781  39.981581 -43.237003  39.471643   -0.322382  -6.074735   \n",
       "4        0.356843 -29.468567  33.367771 -12.860933  -44.425541   3.958389   \n",
       "...           ...        ...        ...        ...         ...        ...   \n",
       "404285  36.746870 -57.793078  75.146161 -20.305723  -19.072270  -2.160282   \n",
       "404286 -32.673037  28.673688  82.408519 -10.283080   46.515741 -55.934617   \n",
       "404287  -8.970818   3.478943  17.787663  -7.907412  -10.202242 -34.997149   \n",
       "404288  64.764972 -76.355071 -26.776399  29.434206  -67.713252   4.832993   \n",
       "404289 -18.173738  34.936834 -11.322893 -10.891564   -7.098439 -64.827279   \n",
       "\n",
       "              94_y       95_y  \n",
       "0        38.112752 -11.592531  \n",
       "1       -22.243213   0.169092  \n",
       "2        77.061497   9.438696  \n",
       "3        -4.417220   5.627428  \n",
       "4       -13.291972  -9.029029  \n",
       "...            ...        ...  \n",
       "404285  105.635542 -16.815833  \n",
       "404286    8.210074 -22.594306  \n",
       "404287   15.290493   5.483173  \n",
       "404288  -63.650805  -5.479479  \n",
       "404289   -4.088562 -31.983831  \n",
       "\n",
       "[404290 rows x 238 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge features\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df_features = df_tm.merge(df_nlp, on='id', how='left')\n",
    "df_features = df_features.merge(df_vectors, on='id', how='left')\n",
    "\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unecessary columns\n",
    "\n",
    "df_features = df_features.drop(['id','qid1','qid2','question1','question2','is_duplicate'], axis=1)\n",
    "type(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>diff_words</th>\n",
       "      <th>caps_count_q1</th>\n",
       "      <th>caps_count_q2</th>\n",
       "      <th>diff_caps</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>15.591466</td>\n",
       "      <td>96.113849</td>\n",
       "      <td>31.001480</td>\n",
       "      <td>-44.172052</td>\n",
       "      <td>21.397091</td>\n",
       "      <td>-46.908810</td>\n",
       "      <td>-100.162247</td>\n",
       "      <td>-1.978221</td>\n",
       "      <td>38.112752</td>\n",
       "      <td>-11.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>-37</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.838611</td>\n",
       "      <td>54.099417</td>\n",
       "      <td>-65.543286</td>\n",
       "      <td>-23.634332</td>\n",
       "      <td>-85.303453</td>\n",
       "      <td>33.143694</td>\n",
       "      <td>-65.774337</td>\n",
       "      <td>28.145018</td>\n",
       "      <td>-22.243213</td>\n",
       "      <td>0.169092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>27.926253</td>\n",
       "      <td>33.117176</td>\n",
       "      <td>66.706154</td>\n",
       "      <td>50.397498</td>\n",
       "      <td>42.266215</td>\n",
       "      <td>-29.920099</td>\n",
       "      <td>-53.378103</td>\n",
       "      <td>-31.755547</td>\n",
       "      <td>77.061497</td>\n",
       "      <td>9.438696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>-15</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.491278</td>\n",
       "      <td>44.788221</td>\n",
       "      <td>6.437781</td>\n",
       "      <td>39.981581</td>\n",
       "      <td>-43.237003</td>\n",
       "      <td>39.471643</td>\n",
       "      <td>-0.322382</td>\n",
       "      <td>-6.074735</td>\n",
       "      <td>-4.417220</td>\n",
       "      <td>5.627428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>44.084751</td>\n",
       "      <td>37.174410</td>\n",
       "      <td>0.356843</td>\n",
       "      <td>-29.468567</td>\n",
       "      <td>33.367771</td>\n",
       "      <td>-12.860933</td>\n",
       "      <td>-44.425541</td>\n",
       "      <td>3.958389</td>\n",
       "      <td>-13.291972</td>\n",
       "      <td>-9.029029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404285</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>39.309001</td>\n",
       "      <td>15.758037</td>\n",
       "      <td>36.746870</td>\n",
       "      <td>-57.793078</td>\n",
       "      <td>75.146161</td>\n",
       "      <td>-20.305723</td>\n",
       "      <td>-19.072270</td>\n",
       "      <td>-2.160282</td>\n",
       "      <td>105.635542</td>\n",
       "      <td>-16.815833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404286</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>6.886801</td>\n",
       "      <td>30.711425</td>\n",
       "      <td>-32.673037</td>\n",
       "      <td>28.673688</td>\n",
       "      <td>82.408519</td>\n",
       "      <td>-10.283080</td>\n",
       "      <td>46.515741</td>\n",
       "      <td>-55.934617</td>\n",
       "      <td>8.210074</td>\n",
       "      <td>-22.594306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404287</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>5.319683</td>\n",
       "      <td>20.635684</td>\n",
       "      <td>-8.970818</td>\n",
       "      <td>3.478943</td>\n",
       "      <td>17.787663</td>\n",
       "      <td>-7.907412</td>\n",
       "      <td>-10.202242</td>\n",
       "      <td>-34.997149</td>\n",
       "      <td>15.290493</td>\n",
       "      <td>5.483173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404288</td>\n",
       "      <td>94</td>\n",
       "      <td>127</td>\n",
       "      <td>-33</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>-8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>45.423385</td>\n",
       "      <td>94.190066</td>\n",
       "      <td>64.764972</td>\n",
       "      <td>-76.355071</td>\n",
       "      <td>-26.776399</td>\n",
       "      <td>29.434206</td>\n",
       "      <td>-67.713252</td>\n",
       "      <td>4.832993</td>\n",
       "      <td>-63.650805</td>\n",
       "      <td>-5.479479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404289</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.524191</td>\n",
       "      <td>28.663685</td>\n",
       "      <td>-18.173738</td>\n",
       "      <td>34.936834</td>\n",
       "      <td>-11.322893</td>\n",
       "      <td>-10.891564</td>\n",
       "      <td>-7.098439</td>\n",
       "      <td>-64.827279</td>\n",
       "      <td>-4.088562</td>\n",
       "      <td>-31.983831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q1len  q2len  diff_len  len_word_q1  len_word_q2  diff_words  \\\n",
       "0          66     57         9           14           12           2   \n",
       "1          51     88       -37            8           13          -5   \n",
       "2          73     59        14           14           10           4   \n",
       "3          50     65       -15           11            9           2   \n",
       "4          76     39        37           13            7           6   \n",
       "...       ...    ...       ...          ...          ...         ...   \n",
       "404285     85     79         6           14           13           1   \n",
       "404286     41     42        -1            8            9          -1   \n",
       "404287     17     17         0            4            3           1   \n",
       "404288     94    127       -33           17           25          -8   \n",
       "404289     37     45        -8            8           10          -2   \n",
       "\n",
       "        caps_count_q1  caps_count_q2  diff_caps  len_char_q1  ...       86_y  \\\n",
       "0                   1              1          0           53  ...  15.591466   \n",
       "1                   5              5          0           44  ... -84.838611   \n",
       "2                   5              5          0           60  ...  27.926253   \n",
       "3                   4              1          3           40  ...  -7.491278   \n",
       "4                   1              1          0           64  ...  44.084751   \n",
       "...               ...            ...        ...          ...  ...        ...   \n",
       "404285              2              7         -5           72  ...  39.309001   \n",
       "404286              1              1          0           34  ...   6.886801   \n",
       "404287              1              1          0           14  ...   5.319683   \n",
       "404288              6              4          2           78  ...  45.423385   \n",
       "404289              1              1          0           30  ... -15.524191   \n",
       "\n",
       "             87_y       88_y       89_y       90_y       91_y        92_y  \\\n",
       "0       96.113849  31.001480 -44.172052  21.397091 -46.908810 -100.162247   \n",
       "1       54.099417 -65.543286 -23.634332 -85.303453  33.143694  -65.774337   \n",
       "2       33.117176  66.706154  50.397498  42.266215 -29.920099  -53.378103   \n",
       "3       44.788221   6.437781  39.981581 -43.237003  39.471643   -0.322382   \n",
       "4       37.174410   0.356843 -29.468567  33.367771 -12.860933  -44.425541   \n",
       "...           ...        ...        ...        ...        ...         ...   \n",
       "404285  15.758037  36.746870 -57.793078  75.146161 -20.305723  -19.072270   \n",
       "404286  30.711425 -32.673037  28.673688  82.408519 -10.283080   46.515741   \n",
       "404287  20.635684  -8.970818   3.478943  17.787663  -7.907412  -10.202242   \n",
       "404288  94.190066  64.764972 -76.355071 -26.776399  29.434206  -67.713252   \n",
       "404289  28.663685 -18.173738  34.936834 -11.322893 -10.891564   -7.098439   \n",
       "\n",
       "             93_y        94_y       95_y  \n",
       "0       -1.978221   38.112752 -11.592531  \n",
       "1       28.145018  -22.243213   0.169092  \n",
       "2      -31.755547   77.061497   9.438696  \n",
       "3       -6.074735   -4.417220   5.627428  \n",
       "4        3.958389  -13.291972  -9.029029  \n",
       "...           ...         ...        ...  \n",
       "404285  -2.160282  105.635542 -16.815833  \n",
       "404286 -55.934617    8.210074 -22.594306  \n",
       "404287 -34.997149   15.290493   5.483173  \n",
       "404288   4.832993  -63.650805  -5.479479  \n",
       "404289 -64.827279   -4.088562 -31.983831  \n",
       "\n",
       "[404290 rows x 232 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1len          0\n",
       "q2len          0\n",
       "diff_len       0\n",
       "len_word_q1    0\n",
       "len_word_q2    0\n",
       "              ..\n",
       "91_y           0\n",
       "92_y           0\n",
       "93_y           0\n",
       "94_y           0\n",
       "95_y           0\n",
       "Length: 232, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for na values\n",
    "\n",
    "df_features.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 232)\n",
      "404290\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training data\n",
    "# Here, x_train means training data, y_train means training labels\n",
    "\n",
    "data_train = df_features\n",
    "\n",
    "# Change datatype to float64\n",
    "cols_csv = list(data_train.columns)\n",
    "x_train = pd.DataFrame(np.array(data_train.values,dtype=np.float64),columns=cols_csv)\n",
    "y_train = list(map(int, y_true.values))\n",
    "\n",
    "print(x_train.shape) \n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.214284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.593862</td>\n",
       "      <td>38.256287</td>\n",
       "      <td>125.235087</td>\n",
       "      <td>-71.082921</td>\n",
       "      <td>-37.907017</td>\n",
       "      <td>-13.690217</td>\n",
       "      <td>58.171292</td>\n",
       "      <td>-55.596645</td>\n",
       "      <td>-55.454169</td>\n",
       "      <td>-75.937598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.717889</td>\n",
       "      <td>9.306832</td>\n",
       "      <td>24.809384</td>\n",
       "      <td>-20.934689</td>\n",
       "      <td>6.793559</td>\n",
       "      <td>-14.271887</td>\n",
       "      <td>-37.130707</td>\n",
       "      <td>-7.595230</td>\n",
       "      <td>-88.665843</td>\n",
       "      <td>58.211807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.813350</td>\n",
       "      <td>31.216904</td>\n",
       "      <td>-33.981025</td>\n",
       "      <td>15.482006</td>\n",
       "      <td>33.123219</td>\n",
       "      <td>-46.651486</td>\n",
       "      <td>-44.865544</td>\n",
       "      <td>-15.787556</td>\n",
       "      <td>3.551124</td>\n",
       "      <td>-35.459945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.824126</td>\n",
       "      <td>-1.324442</td>\n",
       "      <td>-3.411341</td>\n",
       "      <td>26.860650</td>\n",
       "      <td>19.679464</td>\n",
       "      <td>-25.372123</td>\n",
       "      <td>18.991221</td>\n",
       "      <td>-28.173208</td>\n",
       "      <td>-28.481408</td>\n",
       "      <td>-20.523815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.318343</td>\n",
       "      <td>47.191545</td>\n",
       "      <td>-28.551520</td>\n",
       "      <td>14.815438</td>\n",
       "      <td>7.754977</td>\n",
       "      <td>-24.543755</td>\n",
       "      <td>15.449343</td>\n",
       "      <td>14.026138</td>\n",
       "      <td>-13.704267</td>\n",
       "      <td>1.230104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  test_id   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0           0        0  0.599988  0.333330  0.000000  0.000000  0.272725   \n",
       "1           1        1  0.799984  0.571420  0.499975  0.142855  0.714276   \n",
       "2           2        2  0.999967  0.499992  0.666644  0.333328  0.833319   \n",
       "3           3        3  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4           4        4  0.999950  0.666644  0.999900  0.249994  0.749981   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  ...       86_y       87_y  \\\n",
       "0  0.214284           0.0            0.0  ... -21.593862  38.256287   \n",
       "1  0.357140           0.0            0.0  ...  48.717889   9.306832   \n",
       "2  0.357140           0.0            1.0  ...  -7.813350  31.216904   \n",
       "3  0.000000           0.0            0.0  ...  13.824126  -1.324442   \n",
       "4  0.499992           1.0            1.0  ...  13.318343  47.191545   \n",
       "\n",
       "         88_y       89_y       90_y       91_y       92_y       93_y  \\\n",
       "0  125.235087 -71.082921 -37.907017 -13.690217  58.171292 -55.596645   \n",
       "1   24.809384 -20.934689   6.793559 -14.271887 -37.130707  -7.595230   \n",
       "2  -33.981025  15.482006  33.123219 -46.651486 -44.865544 -15.787556   \n",
       "3   -3.411341  26.860650  19.679464 -25.372123  18.991221 -28.173208   \n",
       "4  -28.551520  14.815438   7.754977 -24.543755  15.449343  14.026138   \n",
       "\n",
       "        94_y       95_y  \n",
       "0 -55.454169 -75.937598  \n",
       "1 -88.665843  58.211807  \n",
       "2   3.551124 -35.459945  \n",
       "3 -28.481408 -20.523815  \n",
       "4 -13.704267   1.230104  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vector features from final_features_test.csv\n",
    "\n",
    "df_csv_test = pd.read_csv('final_features_test.csv')\n",
    "df_csv_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 216)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'cwc_min',\n",
       " 'cwc_max',\n",
       " 'csc_min',\n",
       " 'csc_max',\n",
       " 'ctc_min',\n",
       " 'ctc_max',\n",
       " 'last_word_eq',\n",
       " 'first_word_eq',\n",
       " 'abs_len_diff',\n",
       " 'mean_len',\n",
       " 'token_set_ratio',\n",
       " 'token_sort_ratio',\n",
       " 'fuzz_ratio',\n",
       " 'fuzz_partial_ratio',\n",
       " 'longest_substr_ratio',\n",
       " 'q1len',\n",
       " 'q2len',\n",
       " 'q1_n_words',\n",
       " 'q2_n_words',\n",
       " 'word_Common',\n",
       " 'word_Total',\n",
       " 'word_share']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_drop = []\n",
    "columns_drop.append(df_csv_test.columns[0])\n",
    "columns_drop += df_csv_test.columns[2:24].tolist()\n",
    "columns_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the columns to be dropped ['Unnamed: 0', 'cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq', 'first_word_eq', 'abs_len_diff', 'mean_len', 'token_set_ratio', 'token_sort_ratio', 'fuzz_ratio', 'fuzz_partial_ratio', 'longest_substr_ratio', 'q1len', 'q2len', 'q1_n_words', 'q2_n_words', 'word_Common', 'word_Total', 'word_share']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.807789</td>\n",
       "      <td>94.655806</td>\n",
       "      <td>29.802077</td>\n",
       "      <td>-64.234154</td>\n",
       "      <td>-9.277694</td>\n",
       "      <td>-49.877824</td>\n",
       "      <td>51.511347</td>\n",
       "      <td>112.852898</td>\n",
       "      <td>-0.087203</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.593862</td>\n",
       "      <td>38.256287</td>\n",
       "      <td>125.235087</td>\n",
       "      <td>-71.082921</td>\n",
       "      <td>-37.907017</td>\n",
       "      <td>-13.690217</td>\n",
       "      <td>58.171292</td>\n",
       "      <td>-55.596645</td>\n",
       "      <td>-55.454169</td>\n",
       "      <td>-75.937598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.897124</td>\n",
       "      <td>21.283125</td>\n",
       "      <td>17.126591</td>\n",
       "      <td>-105.457273</td>\n",
       "      <td>-10.864314</td>\n",
       "      <td>9.629620</td>\n",
       "      <td>3.914955</td>\n",
       "      <td>23.181845</td>\n",
       "      <td>-81.248861</td>\n",
       "      <td>...</td>\n",
       "      <td>48.717889</td>\n",
       "      <td>9.306832</td>\n",
       "      <td>24.809384</td>\n",
       "      <td>-20.934689</td>\n",
       "      <td>6.793559</td>\n",
       "      <td>-14.271887</td>\n",
       "      <td>-37.130707</td>\n",
       "      <td>-7.595230</td>\n",
       "      <td>-88.665843</td>\n",
       "      <td>58.211807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.807019</td>\n",
       "      <td>-3.833035</td>\n",
       "      <td>-39.952575</td>\n",
       "      <td>-79.576704</td>\n",
       "      <td>-19.552001</td>\n",
       "      <td>-17.994014</td>\n",
       "      <td>-3.919386</td>\n",
       "      <td>48.652988</td>\n",
       "      <td>-65.372602</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.813350</td>\n",
       "      <td>31.216904</td>\n",
       "      <td>-33.981025</td>\n",
       "      <td>15.482006</td>\n",
       "      <td>33.123219</td>\n",
       "      <td>-46.651486</td>\n",
       "      <td>-44.865544</td>\n",
       "      <td>-15.787556</td>\n",
       "      <td>3.551124</td>\n",
       "      <td>-35.459945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44.253134</td>\n",
       "      <td>41.788371</td>\n",
       "      <td>30.544037</td>\n",
       "      <td>-32.077580</td>\n",
       "      <td>20.291117</td>\n",
       "      <td>-27.602314</td>\n",
       "      <td>-89.614907</td>\n",
       "      <td>17.382471</td>\n",
       "      <td>34.562031</td>\n",
       "      <td>...</td>\n",
       "      <td>13.824126</td>\n",
       "      <td>-1.324442</td>\n",
       "      <td>-3.411341</td>\n",
       "      <td>26.860650</td>\n",
       "      <td>19.679464</td>\n",
       "      <td>-25.372123</td>\n",
       "      <td>18.991221</td>\n",
       "      <td>-28.173208</td>\n",
       "      <td>-28.481408</td>\n",
       "      <td>-20.523815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>41.461432</td>\n",
       "      <td>11.422008</td>\n",
       "      <td>21.981641</td>\n",
       "      <td>-55.688798</td>\n",
       "      <td>18.130983</td>\n",
       "      <td>22.543548</td>\n",
       "      <td>-28.407952</td>\n",
       "      <td>36.844785</td>\n",
       "      <td>-39.443902</td>\n",
       "      <td>...</td>\n",
       "      <td>13.318343</td>\n",
       "      <td>47.191545</td>\n",
       "      <td>-28.551520</td>\n",
       "      <td>14.815438</td>\n",
       "      <td>7.754977</td>\n",
       "      <td>-24.543755</td>\n",
       "      <td>15.449343</td>\n",
       "      <td>14.026138</td>\n",
       "      <td>-13.704267</td>\n",
       "      <td>1.230104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345791</td>\n",
       "      <td>2345791</td>\n",
       "      <td>228.731106</td>\n",
       "      <td>104.746842</td>\n",
       "      <td>-57.442300</td>\n",
       "      <td>-16.162305</td>\n",
       "      <td>21.670765</td>\n",
       "      <td>39.921378</td>\n",
       "      <td>50.411566</td>\n",
       "      <td>60.130216</td>\n",
       "      <td>-100.895589</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.679493</td>\n",
       "      <td>23.924009</td>\n",
       "      <td>30.597405</td>\n",
       "      <td>-18.275257</td>\n",
       "      <td>27.869585</td>\n",
       "      <td>-29.048751</td>\n",
       "      <td>-27.496907</td>\n",
       "      <td>-34.687108</td>\n",
       "      <td>44.871046</td>\n",
       "      <td>10.727710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345792</td>\n",
       "      <td>2345792</td>\n",
       "      <td>29.222880</td>\n",
       "      <td>27.854141</td>\n",
       "      <td>56.975427</td>\n",
       "      <td>-27.627264</td>\n",
       "      <td>61.650519</td>\n",
       "      <td>20.190016</td>\n",
       "      <td>0.443094</td>\n",
       "      <td>23.269028</td>\n",
       "      <td>-98.235153</td>\n",
       "      <td>...</td>\n",
       "      <td>41.440152</td>\n",
       "      <td>36.256396</td>\n",
       "      <td>-1.368300</td>\n",
       "      <td>12.766321</td>\n",
       "      <td>34.625701</td>\n",
       "      <td>-25.969023</td>\n",
       "      <td>49.036330</td>\n",
       "      <td>-6.706774</td>\n",
       "      <td>-16.389284</td>\n",
       "      <td>-0.464075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345793</td>\n",
       "      <td>2345793</td>\n",
       "      <td>68.999537</td>\n",
       "      <td>3.775822</td>\n",
       "      <td>82.420922</td>\n",
       "      <td>10.426870</td>\n",
       "      <td>168.312224</td>\n",
       "      <td>-99.611023</td>\n",
       "      <td>-99.559872</td>\n",
       "      <td>47.456131</td>\n",
       "      <td>-93.908065</td>\n",
       "      <td>...</td>\n",
       "      <td>12.216981</td>\n",
       "      <td>-61.148416</td>\n",
       "      <td>79.744077</td>\n",
       "      <td>43.598469</td>\n",
       "      <td>-14.981477</td>\n",
       "      <td>4.705598</td>\n",
       "      <td>3.571221</td>\n",
       "      <td>-35.909301</td>\n",
       "      <td>-11.514811</td>\n",
       "      <td>48.422906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345794</td>\n",
       "      <td>2345794</td>\n",
       "      <td>57.997157</td>\n",
       "      <td>74.850758</td>\n",
       "      <td>40.953900</td>\n",
       "      <td>-46.138095</td>\n",
       "      <td>169.582994</td>\n",
       "      <td>-27.356493</td>\n",
       "      <td>35.563104</td>\n",
       "      <td>133.954845</td>\n",
       "      <td>-114.574158</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.540529</td>\n",
       "      <td>-3.308689</td>\n",
       "      <td>57.458570</td>\n",
       "      <td>-29.407048</td>\n",
       "      <td>-43.692863</td>\n",
       "      <td>18.950830</td>\n",
       "      <td>-39.525612</td>\n",
       "      <td>-18.396463</td>\n",
       "      <td>32.254940</td>\n",
       "      <td>-43.880963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345795</td>\n",
       "      <td>2345795</td>\n",
       "      <td>49.715260</td>\n",
       "      <td>75.883330</td>\n",
       "      <td>-16.167714</td>\n",
       "      <td>-20.333396</td>\n",
       "      <td>61.949988</td>\n",
       "      <td>-1.475873</td>\n",
       "      <td>-50.883314</td>\n",
       "      <td>-56.242930</td>\n",
       "      <td>-127.431814</td>\n",
       "      <td>...</td>\n",
       "      <td>8.746678</td>\n",
       "      <td>9.173925</td>\n",
       "      <td>50.883438</td>\n",
       "      <td>-38.985153</td>\n",
       "      <td>52.681505</td>\n",
       "      <td>-23.949812</td>\n",
       "      <td>-24.394796</td>\n",
       "      <td>31.046030</td>\n",
       "      <td>1.336919</td>\n",
       "      <td>-7.231461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id         0_x         1_x        2_x         3_x         4_x  \\\n",
       "0              0   57.807789   94.655806  29.802077  -64.234154   -9.277694   \n",
       "1              1   12.897124   21.283125  17.126591 -105.457273  -10.864314   \n",
       "2              2    3.807019   -3.833035 -39.952575  -79.576704  -19.552001   \n",
       "3              3   44.253134   41.788371  30.544037  -32.077580   20.291117   \n",
       "4              4   41.461432   11.422008  21.981641  -55.688798   18.130983   \n",
       "...          ...         ...         ...        ...         ...         ...   \n",
       "2345791  2345791  228.731106  104.746842 -57.442300  -16.162305   21.670765   \n",
       "2345792  2345792   29.222880   27.854141  56.975427  -27.627264   61.650519   \n",
       "2345793  2345793   68.999537    3.775822  82.420922   10.426870  168.312224   \n",
       "2345794  2345794   57.997157   74.850758  40.953900  -46.138095  169.582994   \n",
       "2345795  2345795   49.715260   75.883330 -16.167714  -20.333396   61.949988   \n",
       "\n",
       "               5_x        6_x         7_x         8_x  ...       86_y  \\\n",
       "0       -49.877824  51.511347  112.852898   -0.087203  ... -21.593862   \n",
       "1         9.629620   3.914955   23.181845  -81.248861  ...  48.717889   \n",
       "2       -17.994014  -3.919386   48.652988  -65.372602  ...  -7.813350   \n",
       "3       -27.602314 -89.614907   17.382471   34.562031  ...  13.824126   \n",
       "4        22.543548 -28.407952   36.844785  -39.443902  ...  13.318343   \n",
       "...            ...        ...         ...         ...  ...        ...   \n",
       "2345791  39.921378  50.411566   60.130216 -100.895589  ...  -6.679493   \n",
       "2345792  20.190016   0.443094   23.269028  -98.235153  ...  41.440152   \n",
       "2345793 -99.611023 -99.559872   47.456131  -93.908065  ...  12.216981   \n",
       "2345794 -27.356493  35.563104  133.954845 -114.574158  ... -16.540529   \n",
       "2345795  -1.475873 -50.883314  -56.242930 -127.431814  ...   8.746678   \n",
       "\n",
       "              87_y        88_y       89_y       90_y       91_y       92_y  \\\n",
       "0        38.256287  125.235087 -71.082921 -37.907017 -13.690217  58.171292   \n",
       "1         9.306832   24.809384 -20.934689   6.793559 -14.271887 -37.130707   \n",
       "2        31.216904  -33.981025  15.482006  33.123219 -46.651486 -44.865544   \n",
       "3        -1.324442   -3.411341  26.860650  19.679464 -25.372123  18.991221   \n",
       "4        47.191545  -28.551520  14.815438   7.754977 -24.543755  15.449343   \n",
       "...            ...         ...        ...        ...        ...        ...   \n",
       "2345791  23.924009   30.597405 -18.275257  27.869585 -29.048751 -27.496907   \n",
       "2345792  36.256396   -1.368300  12.766321  34.625701 -25.969023  49.036330   \n",
       "2345793 -61.148416   79.744077  43.598469 -14.981477   4.705598   3.571221   \n",
       "2345794  -3.308689   57.458570 -29.407048 -43.692863  18.950830 -39.525612   \n",
       "2345795   9.173925   50.883438 -38.985153  52.681505 -23.949812 -24.394796   \n",
       "\n",
       "              93_y       94_y       95_y  \n",
       "0       -55.596645 -55.454169 -75.937598  \n",
       "1        -7.595230 -88.665843  58.211807  \n",
       "2       -15.787556   3.551124 -35.459945  \n",
       "3       -28.173208 -28.481408 -20.523815  \n",
       "4        14.026138 -13.704267   1.230104  \n",
       "...            ...        ...        ...  \n",
       "2345791 -34.687108  44.871046  10.727710  \n",
       "2345792  -6.706774 -16.389284  -0.464075  \n",
       "2345793 -35.909301 -11.514811  48.422906  \n",
       "2345794 -18.396463  32.254940 -43.880963  \n",
       "2345795  31.046030   1.336919  -7.231461  \n",
       "\n",
       "[2345796 rows x 193 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unecessary columns\n",
    "\n",
    "print(\"These are the columns to be dropped\", columns_drop)\n",
    "\n",
    "df_vectors_test = df_csv_test.drop(columns=columns_drop,axis=1)\n",
    "df_vectors_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features from features_tm_test.csv and features_nlp_test.csv\n",
    "\n",
    "df_tm_test = pd.read_csv('Features/feature_tm_test.csv')\n",
    "df_nlp_test = pd.read_csv('Features/feature_nlp_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>diff_words</th>\n",
       "      <th>caps_count_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>diff_len_char</th>\n",
       "      <th>avg_world_len1</th>\n",
       "      <th>avg_world_len2</th>\n",
       "      <th>diff_avg_word</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>share_2_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>-11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>-8</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.344156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345791</td>\n",
       "      <td>2345791</td>\n",
       "      <td>How do Peaks (TV series): Why did Leland kill ...</td>\n",
       "      <td>What is the most study scene in twin peaks?</td>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>4.454545</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345792</td>\n",
       "      <td>2345792</td>\n",
       "      <td>What does be \"in transit\" mean on FedEx tracking?</td>\n",
       "      <td>How question FedEx packages delivered?</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>-2.244444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345793</td>\n",
       "      <td>2345793</td>\n",
       "      <td>What are some famous Romanian drinks (alcoholi...</td>\n",
       "      <td>Can a non-alcoholic restaurant be a huge success?</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345794</td>\n",
       "      <td>2345794</td>\n",
       "      <td>What were the best and worst things about publ...</td>\n",
       "      <td>What are the best and worst things examination...</td>\n",
       "      <td>119</td>\n",
       "      <td>128</td>\n",
       "      <td>-9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>109</td>\n",
       "      <td>-9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>-0.450000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.342105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345795</td>\n",
       "      <td>2345795</td>\n",
       "      <td>What is the best medication equation erectile ...</td>\n",
       "      <td>How do I out get rid of Erectile Dysfunction?</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id                                          question1  \\\n",
       "0              0  How does the Surface Pro himself 4 compare wit...   \n",
       "1              1  Should I have a hair transplant at age 24? How...   \n",
       "2              2  What but is the best way to send money from Ch...   \n",
       "3              3                        Which food not emulsifiers?   \n",
       "4              4                   How \"aberystwyth\" start reading?   \n",
       "...          ...                                                ...   \n",
       "2345791  2345791  How do Peaks (TV series): Why did Leland kill ...   \n",
       "2345792  2345792  What does be \"in transit\" mean on FedEx tracking?   \n",
       "2345793  2345793  What are some famous Romanian drinks (alcoholi...   \n",
       "2345794  2345794  What were the best and worst things about publ...   \n",
       "2345795  2345795  What is the best medication equation erectile ...   \n",
       "\n",
       "                                                 question2  q1len  q2len  \\\n",
       "0        Why did Microsoft choose core m3 and not core ...     57     68   \n",
       "1              How much cost does hair transplant require?     66     43   \n",
       "2                            What you send money to China?     60     29   \n",
       "3                                        What foods fibre?     27     17   \n",
       "4                           How their can I start reading?     32     30   \n",
       "...                                                    ...    ...    ...   \n",
       "2345791        What is the most study scene in twin peaks?     59     43   \n",
       "2345792             How question FedEx packages delivered?     49     38   \n",
       "2345793  Can a non-alcoholic restaurant be a huge success?     65     49   \n",
       "2345794  What are the best and worst things examination...    119    128   \n",
       "2345795      How do I out get rid of Erectile Dysfunction?     58     45   \n",
       "\n",
       "         diff_len  len_word_q1  len_word_q2  diff_words  caps_count_q1  ...  \\\n",
       "0             -11           11           14          -3              5  ...   \n",
       "1              23           14            7           7              3  ...   \n",
       "2              31           14            6           8              4  ...   \n",
       "3              10            4            3           1              1  ...   \n",
       "4               2            4            6          -2              1  ...   \n",
       "...           ...          ...          ...         ...            ...  ...   \n",
       "2345791        16           11            9           2              8  ...   \n",
       "2345792        11            9            5           4              3  ...   \n",
       "2345793        16            9            8           1              2  ...   \n",
       "2345794        -9           20           20           0              6  ...   \n",
       "2345795        13            8            9          -1              1  ...   \n",
       "\n",
       "         len_char_q1  len_char_q2  diff_len_char  avg_world_len1  \\\n",
       "0                 47           55             -8        4.272727   \n",
       "1                 53           37             16        3.785714   \n",
       "2                 47           24             23        3.357143   \n",
       "3                 24           15              9        6.000000   \n",
       "4                 29           25              4        7.250000   \n",
       "...              ...          ...            ...             ...   \n",
       "2345791           49           35             14        4.454545   \n",
       "2345792           41           34              7        4.555556   \n",
       "2345793           57           42             15        6.333333   \n",
       "2345794          100          109             -9        5.000000   \n",
       "2345795           51           37             14        6.375000   \n",
       "\n",
       "         avg_world_len2  diff_avg_word  word_Common  word_Total  word_share  \\\n",
       "0              3.928571       0.344156          2.0        24.0    0.083333   \n",
       "1              5.285714      -1.500000          4.0        21.0    0.190476   \n",
       "2              4.000000      -0.642857          4.0        18.0    0.222222   \n",
       "3              5.000000       1.000000          0.0         7.0    0.000000   \n",
       "4              4.166667       3.083333          3.0        10.0    0.300000   \n",
       "...                 ...            ...          ...         ...         ...   \n",
       "2345791        3.888889       0.565657          0.0        20.0    0.000000   \n",
       "2345792        6.800000      -2.244444          1.0        14.0    0.071429   \n",
       "2345793        5.250000       1.083333          0.0        16.0    0.000000   \n",
       "2345794        5.450000      -0.450000         17.0        40.0    0.425000   \n",
       "2345795        4.111111       2.263889          2.0        17.0    0.117647   \n",
       "\n",
       "         share_2_gram  \n",
       "0            0.043478  \n",
       "1            0.105263  \n",
       "2            0.055556  \n",
       "3            0.000000  \n",
       "4            0.125000  \n",
       "...               ...  \n",
       "2345791      0.000000  \n",
       "2345792      0.000000  \n",
       "2345793      0.000000  \n",
       "2345794      0.342105  \n",
       "2345795      0.066667  \n",
       "\n",
       "[2345796 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>word_mover_dist</th>\n",
       "      <th>cosine_dist</th>\n",
       "      <th>cityblock_dist</th>\n",
       "      <th>canberra_dist</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>minkowski_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.214284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>5.377619</td>\n",
       "      <td>0.212743</td>\n",
       "      <td>32.914707</td>\n",
       "      <td>158.719900</td>\n",
       "      <td>2.450075</td>\n",
       "      <td>2.450075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>2.885574</td>\n",
       "      <td>0.082187</td>\n",
       "      <td>22.012440</td>\n",
       "      <td>127.354115</td>\n",
       "      <td>1.689144</td>\n",
       "      <td>1.689144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>83</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.004117</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>26.997807</td>\n",
       "      <td>123.466020</td>\n",
       "      <td>1.951432</td>\n",
       "      <td>1.951432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>7.164147</td>\n",
       "      <td>0.391609</td>\n",
       "      <td>73.987938</td>\n",
       "      <td>177.060048</td>\n",
       "      <td>5.201015</td>\n",
       "      <td>5.201015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>3.298204</td>\n",
       "      <td>0.247688</td>\n",
       "      <td>40.107086</td>\n",
       "      <td>147.543857</td>\n",
       "      <td>3.130887</td>\n",
       "      <td>3.130887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345791</td>\n",
       "      <td>2345791</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>6.953441</td>\n",
       "      <td>0.463771</td>\n",
       "      <td>47.484463</td>\n",
       "      <td>190.334052</td>\n",
       "      <td>3.646171</td>\n",
       "      <td>3.646171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345792</td>\n",
       "      <td>2345792</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.111110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>5.286864</td>\n",
       "      <td>0.338680</td>\n",
       "      <td>44.782532</td>\n",
       "      <td>171.177356</td>\n",
       "      <td>3.327089</td>\n",
       "      <td>3.327089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345793</td>\n",
       "      <td>2345793</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.921664</td>\n",
       "      <td>0.214628</td>\n",
       "      <td>36.862625</td>\n",
       "      <td>152.512160</td>\n",
       "      <td>2.793003</td>\n",
       "      <td>2.793003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345794</td>\n",
       "      <td>2345794</td>\n",
       "      <td>0.909083</td>\n",
       "      <td>0.833326</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.849996</td>\n",
       "      <td>0.849996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.381981</td>\n",
       "      <td>0.029951</td>\n",
       "      <td>11.533272</td>\n",
       "      <td>91.066782</td>\n",
       "      <td>0.856469</td>\n",
       "      <td>0.856469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345795</td>\n",
       "      <td>2345795</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.222220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>4.038149</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>33.184307</td>\n",
       "      <td>128.257774</td>\n",
       "      <td>2.410144</td>\n",
       "      <td>2.410144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n",
       "0              0  0.599988  0.333330  0.000000  0.000000  0.272725  0.214284   \n",
       "1              1  0.799984  0.571420  0.499975  0.142855  0.714276  0.357140   \n",
       "2              2  0.999967  0.499992  0.666644  0.333328  0.833319  0.357140   \n",
       "3              3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4              4  0.999950  0.666644  0.999900  0.249994  0.749981  0.499992   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "2345791  2345791  0.249994  0.142855  0.000000  0.000000  0.111110  0.090908   \n",
       "2345792  2345792  0.249994  0.249994  0.000000  0.000000  0.199996  0.111110   \n",
       "2345793  2345793  0.399992  0.399992  0.000000  0.000000  0.222220  0.222220   \n",
       "2345794  2345794  0.909083  0.833326  0.874989  0.777769  0.849996  0.849996   \n",
       "2345795  2345795  0.499988  0.399992  0.000000  0.000000  0.249997  0.222220   \n",
       "\n",
       "         last_word_eq  first_word_eq  abs_len_diff  ...  token_sort_ratio  \\\n",
       "0                 0.0            0.0           3.0  ...                50   \n",
       "1                 0.0            0.0           7.0  ...                58   \n",
       "2                 0.0            1.0           8.0  ...                55   \n",
       "3                 0.0            0.0           1.0  ...                52   \n",
       "4                 1.0            1.0           2.0  ...                66   \n",
       "...               ...            ...           ...  ...               ...   \n",
       "2345791           0.0            0.0           2.0  ...                39   \n",
       "2345792           0.0            0.0           4.0  ...                36   \n",
       "2345793           0.0            0.0           0.0  ...                52   \n",
       "2345794           1.0            1.0           0.0  ...                79   \n",
       "2345795           1.0            0.0           1.0  ...                50   \n",
       "\n",
       "         fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \\\n",
       "0                37                  45              0.241379   \n",
       "1                47                  56              0.386364   \n",
       "2                57                  83              0.400000   \n",
       "3                52                  53              0.277778   \n",
       "4                70                  73              0.483871   \n",
       "...             ...                 ...                   ...   \n",
       "2345791          18                  30              0.159091   \n",
       "2345792          42                  50              0.230769   \n",
       "2345793          32                  51              0.300000   \n",
       "2345794          87                  84              0.416667   \n",
       "2345795          57                  66              0.478261   \n",
       "\n",
       "         word_mover_dist  cosine_dist  cityblock_dist  canberra_dist  \\\n",
       "0               5.377619     0.212743       32.914707     158.719900   \n",
       "1               2.885574     0.082187       22.012440     127.354115   \n",
       "2               3.004117     0.094164       26.997807     123.466020   \n",
       "3               7.164147     0.391609       73.987938     177.060048   \n",
       "4               3.298204     0.247688       40.107086     147.543857   \n",
       "...                  ...          ...             ...            ...   \n",
       "2345791         6.953441     0.463771       47.484463     190.334052   \n",
       "2345792         5.286864     0.338680       44.782532     171.177356   \n",
       "2345793         4.921664     0.214628       36.862625     152.512160   \n",
       "2345794         1.381981     0.029951       11.533272      91.066782   \n",
       "2345795         4.038149     0.119501       33.184307     128.257774   \n",
       "\n",
       "         euclidean_dist  minkowski_dist  \n",
       "0              2.450075        2.450075  \n",
       "1              1.689144        1.689144  \n",
       "2              1.951432        1.951432  \n",
       "3              5.201015        5.201015  \n",
       "4              3.130887        3.130887  \n",
       "...                 ...             ...  \n",
       "2345791        3.646171        3.646171  \n",
       "2345792        3.327089        3.327089  \n",
       "2345793        2.793003        2.793003  \n",
       "2345794        0.856469        0.856469  \n",
       "2345795        2.410144        2.410144  \n",
       "\n",
       "[2345796 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>diff_words</th>\n",
       "      <th>caps_count_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>-11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.593862</td>\n",
       "      <td>38.256287</td>\n",
       "      <td>125.235087</td>\n",
       "      <td>-71.082921</td>\n",
       "      <td>-37.907017</td>\n",
       "      <td>-13.690217</td>\n",
       "      <td>58.171292</td>\n",
       "      <td>-55.596645</td>\n",
       "      <td>-55.454169</td>\n",
       "      <td>-75.937598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>48.717889</td>\n",
       "      <td>9.306832</td>\n",
       "      <td>24.809384</td>\n",
       "      <td>-20.934689</td>\n",
       "      <td>6.793559</td>\n",
       "      <td>-14.271887</td>\n",
       "      <td>-37.130707</td>\n",
       "      <td>-7.595230</td>\n",
       "      <td>-88.665843</td>\n",
       "      <td>58.211807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.813350</td>\n",
       "      <td>31.216904</td>\n",
       "      <td>-33.981025</td>\n",
       "      <td>15.482006</td>\n",
       "      <td>33.123219</td>\n",
       "      <td>-46.651486</td>\n",
       "      <td>-44.865544</td>\n",
       "      <td>-15.787556</td>\n",
       "      <td>3.551124</td>\n",
       "      <td>-35.459945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.824126</td>\n",
       "      <td>-1.324442</td>\n",
       "      <td>-3.411341</td>\n",
       "      <td>26.860650</td>\n",
       "      <td>19.679464</td>\n",
       "      <td>-25.372123</td>\n",
       "      <td>18.991221</td>\n",
       "      <td>-28.173208</td>\n",
       "      <td>-28.481408</td>\n",
       "      <td>-20.523815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.318343</td>\n",
       "      <td>47.191545</td>\n",
       "      <td>-28.551520</td>\n",
       "      <td>14.815438</td>\n",
       "      <td>7.754977</td>\n",
       "      <td>-24.543755</td>\n",
       "      <td>15.449343</td>\n",
       "      <td>14.026138</td>\n",
       "      <td>-13.704267</td>\n",
       "      <td>1.230104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345791</td>\n",
       "      <td>2345791</td>\n",
       "      <td>How do Peaks (TV series): Why did Leland kill ...</td>\n",
       "      <td>What is the most study scene in twin peaks?</td>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.679493</td>\n",
       "      <td>23.924009</td>\n",
       "      <td>30.597405</td>\n",
       "      <td>-18.275257</td>\n",
       "      <td>27.869585</td>\n",
       "      <td>-29.048751</td>\n",
       "      <td>-27.496907</td>\n",
       "      <td>-34.687108</td>\n",
       "      <td>44.871046</td>\n",
       "      <td>10.727710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345792</td>\n",
       "      <td>2345792</td>\n",
       "      <td>What does be \"in transit\" mean on FedEx tracking?</td>\n",
       "      <td>How question FedEx packages delivered?</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>41.440152</td>\n",
       "      <td>36.256396</td>\n",
       "      <td>-1.368300</td>\n",
       "      <td>12.766321</td>\n",
       "      <td>34.625701</td>\n",
       "      <td>-25.969023</td>\n",
       "      <td>49.036330</td>\n",
       "      <td>-6.706774</td>\n",
       "      <td>-16.389284</td>\n",
       "      <td>-0.464075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345793</td>\n",
       "      <td>2345793</td>\n",
       "      <td>What are some famous Romanian drinks (alcoholi...</td>\n",
       "      <td>Can a non-alcoholic restaurant be a huge success?</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.216981</td>\n",
       "      <td>-61.148416</td>\n",
       "      <td>79.744077</td>\n",
       "      <td>43.598469</td>\n",
       "      <td>-14.981477</td>\n",
       "      <td>4.705598</td>\n",
       "      <td>3.571221</td>\n",
       "      <td>-35.909301</td>\n",
       "      <td>-11.514811</td>\n",
       "      <td>48.422906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345794</td>\n",
       "      <td>2345794</td>\n",
       "      <td>What were the best and worst things about publ...</td>\n",
       "      <td>What are the best and worst things examination...</td>\n",
       "      <td>119</td>\n",
       "      <td>128</td>\n",
       "      <td>-9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.540529</td>\n",
       "      <td>-3.308689</td>\n",
       "      <td>57.458570</td>\n",
       "      <td>-29.407048</td>\n",
       "      <td>-43.692863</td>\n",
       "      <td>18.950830</td>\n",
       "      <td>-39.525612</td>\n",
       "      <td>-18.396463</td>\n",
       "      <td>32.254940</td>\n",
       "      <td>-43.880963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345795</td>\n",
       "      <td>2345795</td>\n",
       "      <td>What is the best medication equation erectile ...</td>\n",
       "      <td>How do I out get rid of Erectile Dysfunction?</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.746678</td>\n",
       "      <td>9.173925</td>\n",
       "      <td>50.883438</td>\n",
       "      <td>-38.985153</td>\n",
       "      <td>52.681505</td>\n",
       "      <td>-23.949812</td>\n",
       "      <td>-24.394796</td>\n",
       "      <td>31.046030</td>\n",
       "      <td>1.336919</td>\n",
       "      <td>-7.231461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows Ã— 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id                                          question1  \\\n",
       "0              0  How does the Surface Pro himself 4 compare wit...   \n",
       "1              1  Should I have a hair transplant at age 24? How...   \n",
       "2              2  What but is the best way to send money from Ch...   \n",
       "3              3                        Which food not emulsifiers?   \n",
       "4              4                   How \"aberystwyth\" start reading?   \n",
       "...          ...                                                ...   \n",
       "2345791  2345791  How do Peaks (TV series): Why did Leland kill ...   \n",
       "2345792  2345792  What does be \"in transit\" mean on FedEx tracking?   \n",
       "2345793  2345793  What are some famous Romanian drinks (alcoholi...   \n",
       "2345794  2345794  What were the best and worst things about publ...   \n",
       "2345795  2345795  What is the best medication equation erectile ...   \n",
       "\n",
       "                                                 question2  q1len  q2len  \\\n",
       "0        Why did Microsoft choose core m3 and not core ...     57     68   \n",
       "1              How much cost does hair transplant require?     66     43   \n",
       "2                            What you send money to China?     60     29   \n",
       "3                                        What foods fibre?     27     17   \n",
       "4                           How their can I start reading?     32     30   \n",
       "...                                                    ...    ...    ...   \n",
       "2345791        What is the most study scene in twin peaks?     59     43   \n",
       "2345792             How question FedEx packages delivered?     49     38   \n",
       "2345793  Can a non-alcoholic restaurant be a huge success?     65     49   \n",
       "2345794  What are the best and worst things examination...    119    128   \n",
       "2345795      How do I out get rid of Erectile Dysfunction?     58     45   \n",
       "\n",
       "         diff_len  len_word_q1  len_word_q2  diff_words  caps_count_q1  ...  \\\n",
       "0             -11           11           14          -3              5  ...   \n",
       "1              23           14            7           7              3  ...   \n",
       "2              31           14            6           8              4  ...   \n",
       "3              10            4            3           1              1  ...   \n",
       "4               2            4            6          -2              1  ...   \n",
       "...           ...          ...          ...         ...            ...  ...   \n",
       "2345791        16           11            9           2              8  ...   \n",
       "2345792        11            9            5           4              3  ...   \n",
       "2345793        16            9            8           1              2  ...   \n",
       "2345794        -9           20           20           0              6  ...   \n",
       "2345795        13            8            9          -1              1  ...   \n",
       "\n",
       "              86_y       87_y        88_y       89_y       90_y       91_y  \\\n",
       "0       -21.593862  38.256287  125.235087 -71.082921 -37.907017 -13.690217   \n",
       "1        48.717889   9.306832   24.809384 -20.934689   6.793559 -14.271887   \n",
       "2        -7.813350  31.216904  -33.981025  15.482006  33.123219 -46.651486   \n",
       "3        13.824126  -1.324442   -3.411341  26.860650  19.679464 -25.372123   \n",
       "4        13.318343  47.191545  -28.551520  14.815438   7.754977 -24.543755   \n",
       "...            ...        ...         ...        ...        ...        ...   \n",
       "2345791  -6.679493  23.924009   30.597405 -18.275257  27.869585 -29.048751   \n",
       "2345792  41.440152  36.256396   -1.368300  12.766321  34.625701 -25.969023   \n",
       "2345793  12.216981 -61.148416   79.744077  43.598469 -14.981477   4.705598   \n",
       "2345794 -16.540529  -3.308689   57.458570 -29.407048 -43.692863  18.950830   \n",
       "2345795   8.746678   9.173925   50.883438 -38.985153  52.681505 -23.949812   \n",
       "\n",
       "              92_y       93_y       94_y       95_y  \n",
       "0        58.171292 -55.596645 -55.454169 -75.937598  \n",
       "1       -37.130707  -7.595230 -88.665843  58.211807  \n",
       "2       -44.865544 -15.787556   3.551124 -35.459945  \n",
       "3        18.991221 -28.173208 -28.481408 -20.523815  \n",
       "4        15.449343  14.026138 -13.704267   1.230104  \n",
       "...            ...        ...        ...        ...  \n",
       "2345791 -27.496907 -34.687108  44.871046  10.727710  \n",
       "2345792  49.036330  -6.706774 -16.389284  -0.464075  \n",
       "2345793   3.571221 -35.909301 -11.514811  48.422906  \n",
       "2345794 -39.525612 -18.396463  32.254940 -43.880963  \n",
       "2345795 -24.394796  31.046030   1.336919  -7.231461  \n",
       "\n",
       "[2345796 rows x 235 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge features\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df_features_test = df_tm_test.merge(df_nlp_test, on='test_id', how='left')\n",
    "df_features_test = df_features_test.merge(df_vectors_test, on='test_id', how='left')\n",
    "\n",
    "df_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>diff_words</th>\n",
       "      <th>caps_count_q1</th>\n",
       "      <th>caps_count_q2</th>\n",
       "      <th>diff_caps</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>-11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.593862</td>\n",
       "      <td>38.256287</td>\n",
       "      <td>125.235087</td>\n",
       "      <td>-71.082921</td>\n",
       "      <td>-37.907017</td>\n",
       "      <td>-13.690217</td>\n",
       "      <td>58.171292</td>\n",
       "      <td>-55.596645</td>\n",
       "      <td>-55.454169</td>\n",
       "      <td>-75.937598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>48.717889</td>\n",
       "      <td>9.306832</td>\n",
       "      <td>24.809384</td>\n",
       "      <td>-20.934689</td>\n",
       "      <td>6.793559</td>\n",
       "      <td>-14.271887</td>\n",
       "      <td>-37.130707</td>\n",
       "      <td>-7.595230</td>\n",
       "      <td>-88.665843</td>\n",
       "      <td>58.211807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.813350</td>\n",
       "      <td>31.216904</td>\n",
       "      <td>-33.981025</td>\n",
       "      <td>15.482006</td>\n",
       "      <td>33.123219</td>\n",
       "      <td>-46.651486</td>\n",
       "      <td>-44.865544</td>\n",
       "      <td>-15.787556</td>\n",
       "      <td>3.551124</td>\n",
       "      <td>-35.459945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>13.824126</td>\n",
       "      <td>-1.324442</td>\n",
       "      <td>-3.411341</td>\n",
       "      <td>26.860650</td>\n",
       "      <td>19.679464</td>\n",
       "      <td>-25.372123</td>\n",
       "      <td>18.991221</td>\n",
       "      <td>-28.173208</td>\n",
       "      <td>-28.481408</td>\n",
       "      <td>-20.523815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>13.318343</td>\n",
       "      <td>47.191545</td>\n",
       "      <td>-28.551520</td>\n",
       "      <td>14.815438</td>\n",
       "      <td>7.754977</td>\n",
       "      <td>-24.543755</td>\n",
       "      <td>15.449343</td>\n",
       "      <td>14.026138</td>\n",
       "      <td>-13.704267</td>\n",
       "      <td>1.230104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345791</td>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.679493</td>\n",
       "      <td>23.924009</td>\n",
       "      <td>30.597405</td>\n",
       "      <td>-18.275257</td>\n",
       "      <td>27.869585</td>\n",
       "      <td>-29.048751</td>\n",
       "      <td>-27.496907</td>\n",
       "      <td>-34.687108</td>\n",
       "      <td>44.871046</td>\n",
       "      <td>10.727710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345792</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41.440152</td>\n",
       "      <td>36.256396</td>\n",
       "      <td>-1.368300</td>\n",
       "      <td>12.766321</td>\n",
       "      <td>34.625701</td>\n",
       "      <td>-25.969023</td>\n",
       "      <td>49.036330</td>\n",
       "      <td>-6.706774</td>\n",
       "      <td>-16.389284</td>\n",
       "      <td>-0.464075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345793</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>12.216981</td>\n",
       "      <td>-61.148416</td>\n",
       "      <td>79.744077</td>\n",
       "      <td>43.598469</td>\n",
       "      <td>-14.981477</td>\n",
       "      <td>4.705598</td>\n",
       "      <td>3.571221</td>\n",
       "      <td>-35.909301</td>\n",
       "      <td>-11.514811</td>\n",
       "      <td>48.422906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345794</td>\n",
       "      <td>119</td>\n",
       "      <td>128</td>\n",
       "      <td>-9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.540529</td>\n",
       "      <td>-3.308689</td>\n",
       "      <td>57.458570</td>\n",
       "      <td>-29.407048</td>\n",
       "      <td>-43.692863</td>\n",
       "      <td>18.950830</td>\n",
       "      <td>-39.525612</td>\n",
       "      <td>-18.396463</td>\n",
       "      <td>32.254940</td>\n",
       "      <td>-43.880963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345795</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>8.746678</td>\n",
       "      <td>9.173925</td>\n",
       "      <td>50.883438</td>\n",
       "      <td>-38.985153</td>\n",
       "      <td>52.681505</td>\n",
       "      <td>-23.949812</td>\n",
       "      <td>-24.394796</td>\n",
       "      <td>31.046030</td>\n",
       "      <td>1.336919</td>\n",
       "      <td>-7.231461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows Ã— 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         q1len  q2len  diff_len  len_word_q1  len_word_q2  diff_words  \\\n",
       "0           57     68       -11           11           14          -3   \n",
       "1           66     43        23           14            7           7   \n",
       "2           60     29        31           14            6           8   \n",
       "3           27     17        10            4            3           1   \n",
       "4           32     30         2            4            6          -2   \n",
       "...        ...    ...       ...          ...          ...         ...   \n",
       "2345791     59     43        16           11            9           2   \n",
       "2345792     49     38        11            9            5           4   \n",
       "2345793     65     49        16            9            8           1   \n",
       "2345794    119    128        -9           20           20           0   \n",
       "2345795     58     45        13            8            9          -1   \n",
       "\n",
       "         caps_count_q1  caps_count_q2  diff_caps  len_char_q1  ...       86_y  \\\n",
       "0                    5              4          1           47  ... -21.593862   \n",
       "1                    3              1          2           53  ...  48.717889   \n",
       "2                    4              2          2           47  ...  -7.813350   \n",
       "3                    1              1          0           24  ...  13.824126   \n",
       "4                    1              2         -1           29  ...  13.318343   \n",
       "...                ...            ...        ...          ...  ...        ...   \n",
       "2345791              8              1          7           49  ...  -6.679493   \n",
       "2345792              3              3          0           41  ...  41.440152   \n",
       "2345793              2              1          1           57  ...  12.216981   \n",
       "2345794              6              6          0          100  ... -16.540529   \n",
       "2345795              1              4         -3           51  ...   8.746678   \n",
       "\n",
       "              87_y        88_y       89_y       90_y       91_y       92_y  \\\n",
       "0        38.256287  125.235087 -71.082921 -37.907017 -13.690217  58.171292   \n",
       "1         9.306832   24.809384 -20.934689   6.793559 -14.271887 -37.130707   \n",
       "2        31.216904  -33.981025  15.482006  33.123219 -46.651486 -44.865544   \n",
       "3        -1.324442   -3.411341  26.860650  19.679464 -25.372123  18.991221   \n",
       "4        47.191545  -28.551520  14.815438   7.754977 -24.543755  15.449343   \n",
       "...            ...         ...        ...        ...        ...        ...   \n",
       "2345791  23.924009   30.597405 -18.275257  27.869585 -29.048751 -27.496907   \n",
       "2345792  36.256396   -1.368300  12.766321  34.625701 -25.969023  49.036330   \n",
       "2345793 -61.148416   79.744077  43.598469 -14.981477   4.705598   3.571221   \n",
       "2345794  -3.308689   57.458570 -29.407048 -43.692863  18.950830 -39.525612   \n",
       "2345795   9.173925   50.883438 -38.985153  52.681505 -23.949812 -24.394796   \n",
       "\n",
       "              93_y       94_y       95_y  \n",
       "0       -55.596645 -55.454169 -75.937598  \n",
       "1        -7.595230 -88.665843  58.211807  \n",
       "2       -15.787556   3.551124 -35.459945  \n",
       "3       -28.173208 -28.481408 -20.523815  \n",
       "4        14.026138 -13.704267   1.230104  \n",
       "...            ...        ...        ...  \n",
       "2345791 -34.687108  44.871046  10.727710  \n",
       "2345792  -6.706774 -16.389284  -0.464075  \n",
       "2345793 -35.909301 -11.514811  48.422906  \n",
       "2345794 -18.396463  32.254940 -43.880963  \n",
       "2345795  31.046030   1.336919  -7.231461  \n",
       "\n",
       "[2345796 rows x 232 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unecessary columns\n",
    "\n",
    "df_features_test = df_features_test.drop(['test_id','question1','question2'], axis=1)\n",
    "df_features_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1len          0\n",
       "q2len          0\n",
       "diff_len       0\n",
       "len_word_q1    0\n",
       "len_word_q2    0\n",
       "              ..\n",
       "91_y           0\n",
       "92_y           0\n",
       "93_y           0\n",
       "94_y           0\n",
       "95_y           0\n",
       "Length: 232, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for na values\n",
    "\n",
    "df_features_test.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>diff_words</th>\n",
       "      <th>caps_count_q1</th>\n",
       "      <th>caps_count_q2</th>\n",
       "      <th>diff_caps</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.593862</td>\n",
       "      <td>38.256287</td>\n",
       "      <td>125.235087</td>\n",
       "      <td>-71.082921</td>\n",
       "      <td>-37.907017</td>\n",
       "      <td>-13.690217</td>\n",
       "      <td>58.171292</td>\n",
       "      <td>-55.596645</td>\n",
       "      <td>-55.454169</td>\n",
       "      <td>-75.937598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.717889</td>\n",
       "      <td>9.306832</td>\n",
       "      <td>24.809384</td>\n",
       "      <td>-20.934689</td>\n",
       "      <td>6.793559</td>\n",
       "      <td>-14.271887</td>\n",
       "      <td>-37.130707</td>\n",
       "      <td>-7.595230</td>\n",
       "      <td>-88.665843</td>\n",
       "      <td>58.211807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.813350</td>\n",
       "      <td>31.216904</td>\n",
       "      <td>-33.981025</td>\n",
       "      <td>15.482006</td>\n",
       "      <td>33.123219</td>\n",
       "      <td>-46.651486</td>\n",
       "      <td>-44.865544</td>\n",
       "      <td>-15.787556</td>\n",
       "      <td>3.551124</td>\n",
       "      <td>-35.459945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.824126</td>\n",
       "      <td>-1.324442</td>\n",
       "      <td>-3.411341</td>\n",
       "      <td>26.860650</td>\n",
       "      <td>19.679464</td>\n",
       "      <td>-25.372123</td>\n",
       "      <td>18.991221</td>\n",
       "      <td>-28.173208</td>\n",
       "      <td>-28.481408</td>\n",
       "      <td>-20.523815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.318343</td>\n",
       "      <td>47.191545</td>\n",
       "      <td>-28.551520</td>\n",
       "      <td>14.815438</td>\n",
       "      <td>7.754977</td>\n",
       "      <td>-24.543755</td>\n",
       "      <td>15.449343</td>\n",
       "      <td>14.026138</td>\n",
       "      <td>-13.704267</td>\n",
       "      <td>1.230104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345791</td>\n",
       "      <td>59.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.679493</td>\n",
       "      <td>23.924009</td>\n",
       "      <td>30.597405</td>\n",
       "      <td>-18.275257</td>\n",
       "      <td>27.869585</td>\n",
       "      <td>-29.048751</td>\n",
       "      <td>-27.496907</td>\n",
       "      <td>-34.687108</td>\n",
       "      <td>44.871046</td>\n",
       "      <td>10.727710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345792</td>\n",
       "      <td>49.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.440152</td>\n",
       "      <td>36.256396</td>\n",
       "      <td>-1.368300</td>\n",
       "      <td>12.766321</td>\n",
       "      <td>34.625701</td>\n",
       "      <td>-25.969023</td>\n",
       "      <td>49.036330</td>\n",
       "      <td>-6.706774</td>\n",
       "      <td>-16.389284</td>\n",
       "      <td>-0.464075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345793</td>\n",
       "      <td>65.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.216981</td>\n",
       "      <td>-61.148416</td>\n",
       "      <td>79.744077</td>\n",
       "      <td>43.598469</td>\n",
       "      <td>-14.981477</td>\n",
       "      <td>4.705598</td>\n",
       "      <td>3.571221</td>\n",
       "      <td>-35.909301</td>\n",
       "      <td>-11.514811</td>\n",
       "      <td>48.422906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345794</td>\n",
       "      <td>119.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.540529</td>\n",
       "      <td>-3.308689</td>\n",
       "      <td>57.458570</td>\n",
       "      <td>-29.407048</td>\n",
       "      <td>-43.692863</td>\n",
       "      <td>18.950830</td>\n",
       "      <td>-39.525612</td>\n",
       "      <td>-18.396463</td>\n",
       "      <td>32.254940</td>\n",
       "      <td>-43.880963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345795</td>\n",
       "      <td>58.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.746678</td>\n",
       "      <td>9.173925</td>\n",
       "      <td>50.883438</td>\n",
       "      <td>-38.985153</td>\n",
       "      <td>52.681505</td>\n",
       "      <td>-23.949812</td>\n",
       "      <td>-24.394796</td>\n",
       "      <td>31.046030</td>\n",
       "      <td>1.336919</td>\n",
       "      <td>-7.231461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows Ã— 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         q1len  q2len  diff_len  len_word_q1  len_word_q2  diff_words  \\\n",
       "0         57.0   68.0     -11.0         11.0         14.0        -3.0   \n",
       "1         66.0   43.0      23.0         14.0          7.0         7.0   \n",
       "2         60.0   29.0      31.0         14.0          6.0         8.0   \n",
       "3         27.0   17.0      10.0          4.0          3.0         1.0   \n",
       "4         32.0   30.0       2.0          4.0          6.0        -2.0   \n",
       "...        ...    ...       ...          ...          ...         ...   \n",
       "2345791   59.0   43.0      16.0         11.0          9.0         2.0   \n",
       "2345792   49.0   38.0      11.0          9.0          5.0         4.0   \n",
       "2345793   65.0   49.0      16.0          9.0          8.0         1.0   \n",
       "2345794  119.0  128.0      -9.0         20.0         20.0         0.0   \n",
       "2345795   58.0   45.0      13.0          8.0          9.0        -1.0   \n",
       "\n",
       "         caps_count_q1  caps_count_q2  diff_caps  len_char_q1  ...       86_y  \\\n",
       "0                  5.0            4.0        1.0         47.0  ... -21.593862   \n",
       "1                  3.0            1.0        2.0         53.0  ...  48.717889   \n",
       "2                  4.0            2.0        2.0         47.0  ...  -7.813350   \n",
       "3                  1.0            1.0        0.0         24.0  ...  13.824126   \n",
       "4                  1.0            2.0       -1.0         29.0  ...  13.318343   \n",
       "...                ...            ...        ...          ...  ...        ...   \n",
       "2345791            8.0            1.0        7.0         49.0  ...  -6.679493   \n",
       "2345792            3.0            3.0        0.0         41.0  ...  41.440152   \n",
       "2345793            2.0            1.0        1.0         57.0  ...  12.216981   \n",
       "2345794            6.0            6.0        0.0        100.0  ... -16.540529   \n",
       "2345795            1.0            4.0       -3.0         51.0  ...   8.746678   \n",
       "\n",
       "              87_y        88_y       89_y       90_y       91_y       92_y  \\\n",
       "0        38.256287  125.235087 -71.082921 -37.907017 -13.690217  58.171292   \n",
       "1         9.306832   24.809384 -20.934689   6.793559 -14.271887 -37.130707   \n",
       "2        31.216904  -33.981025  15.482006  33.123219 -46.651486 -44.865544   \n",
       "3        -1.324442   -3.411341  26.860650  19.679464 -25.372123  18.991221   \n",
       "4        47.191545  -28.551520  14.815438   7.754977 -24.543755  15.449343   \n",
       "...            ...         ...        ...        ...        ...        ...   \n",
       "2345791  23.924009   30.597405 -18.275257  27.869585 -29.048751 -27.496907   \n",
       "2345792  36.256396   -1.368300  12.766321  34.625701 -25.969023  49.036330   \n",
       "2345793 -61.148416   79.744077  43.598469 -14.981477   4.705598   3.571221   \n",
       "2345794  -3.308689   57.458570 -29.407048 -43.692863  18.950830 -39.525612   \n",
       "2345795   9.173925   50.883438 -38.985153  52.681505 -23.949812 -24.394796   \n",
       "\n",
       "              93_y       94_y       95_y  \n",
       "0       -55.596645 -55.454169 -75.937598  \n",
       "1        -7.595230 -88.665843  58.211807  \n",
       "2       -15.787556   3.551124 -35.459945  \n",
       "3       -28.173208 -28.481408 -20.523815  \n",
       "4        14.026138 -13.704267   1.230104  \n",
       "...            ...        ...        ...  \n",
       "2345791 -34.687108  44.871046  10.727710  \n",
       "2345792  -6.706774 -16.389284  -0.464075  \n",
       "2345793 -35.909301 -11.514811  48.422906  \n",
       "2345794 -18.396463  32.254940 -43.880963  \n",
       "2345795  31.046030   1.336919  -7.231461  \n",
       "\n",
       "[2345796 rows x 232 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the testing data\n",
    "# Here, x_test means test data\n",
    "cols_csv = list(df_features_test.columns)\n",
    "x_test = pd.DataFrame(np.array(df_features_test.values,dtype=np.float64),columns=cols_csv)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1len          float64\n",
       "q2len          float64\n",
       "diff_len       float64\n",
       "len_word_q1    float64\n",
       "len_word_q2    float64\n",
       "                ...   \n",
       "91_y           float64\n",
       "92_y           float64\n",
       "93_y           float64\n",
       "94_y           float64\n",
       "95_y           float64\n",
       "Length: 232, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_test = 2345796 rows Ã— 232 columns \n",
    "\n",
    "y_predict = ?\n",
    "\n",
    "x_train = 404290 rows Ã— 232 columns\n",
    "\n",
    "y_train = 404290 rows\n",
    "\n",
    "- x_train_splited: used for model training\n",
    "- y_train_splited: used for model training\n",
    "- x_test_splited: used for model training\n",
    "- y_test_splited: used for model training\n",
    "\n",
    "\n",
    "- **By Comparing the results with the first iteration in Linear Regression model, apparently the results of the second are better, it is because there are more features. So in the random forest model and xgboost model, I will only do the prediction based on the best model parameters in the 1st. itration in order to save time.**\n",
    "  - The 1st iteration is in `models.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.fillna(0)\n",
    "# x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train_splited data : (283003, 232)\n",
      "Number of data points in test_splited data : (121287, 232)\n",
      "Number of data points in train data: (404290, 232)\n",
      "Number of data points in test data: (2345796, 232)\n"
     ]
    }
   ],
   "source": [
    "# Preparations\n",
    "# Random Split the Train data\n",
    "x_train_splited, x_test_splited, y_train_splited, y_test_splited = train_test_split(x_train, y_train, stratify=y_train, test_size=0.3,random_state=13)\n",
    "\n",
    "print(\"Number of data points in train_splited data :\",x_train_splited.shape)\n",
    "print(\"Number of data points in test_splited data :\",x_test_splited.shape)\n",
    "print('Number of data points in train data:', x_train.shape)\n",
    "print('Number of data points in test data:', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-level parameters\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_1: Linear Regression with Hyperparameter Tuning\n",
    "\n",
    "I plan to use SGD claasifier as our linear model, SGD is sensitive to feature scaling, so i did scaling as a preprocessing. `Scored: 0.424`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1len          0\n",
      "q2len          0\n",
      "diff_len       0\n",
      "len_word_q1    0\n",
      "len_word_q2    0\n",
      "              ..\n",
      "91_y           0\n",
      "92_y           0\n",
      "93_y           0\n",
      "94_y           0\n",
      "95_y           0\n",
      "Length: 232, dtype: int64\n",
      "------------------\n",
      "q1len          0\n",
      "q2len          0\n",
      "diff_len       0\n",
      "len_word_q1    0\n",
      "len_word_q2    0\n",
      "              ..\n",
      "91_y           0\n",
      "92_y           0\n",
      "93_y           0\n",
      "94_y           0\n",
      "95_y           0\n",
      "Length: 232, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check null values in the training and testing data\n",
    "na_num_train = x_train.isna().sum()\n",
    "na_num_test = x_test.isna().sum()\n",
    "print(na_num_train)\n",
    "print('------------------')\n",
    "print(na_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation: Apply scaling to train and test data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "x_train_model_1 = scale.fit_transform(x_train)\n",
    "x_test_model_1 = scale.transform(x_test)\n",
    "\n",
    "x_train_splited_model_1 = scale.fit_transform(x_train_splited)\n",
    "x_test_splited_model_1 = scale.transform(x_test_splited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of alpha =  1e-05 The log loss is: 0.4928641312616705\n",
      "For values of alpha =  0.0001 The log loss is: 0.4860320918392338\n",
      "For values of alpha =  0.001 The log loss is: 0.480195036583203\n",
      "For values of alpha =  0.01 The log loss is: 0.48493305512516205\n",
      "For values of alpha =  0.1 The log loss is: 0.5042260077823576\n",
      "For values of alpha =  1 The log loss is: 0.5314124629398347\n",
      "For values of alpha =  10 The log loss is: 0.5509175576145035\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of best alpha =  0.001 The train log loss is: 0.4792286155567768\n",
      "Total number of data points : 2345796\n"
     ]
    }
   ],
   "source": [
    "# Traning and Tesing\n",
    "\n",
    "# Training, use prepared data to train the model.\n",
    "alpha = [10 ** x for x in range(-5, 2)] # hyperparam for SGD classifier.\n",
    "y_train_model_1 = y_train\n",
    "y_train_splited_model_1 = y_train_splited\n",
    "y_test_splited_model_1 = y_test_splited\n",
    "\n",
    "# read more about SGDClassifier() at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# ------------------------------\n",
    "# default parameters\n",
    "# SGDClassifier(loss=â€™hingeâ€™, penalty=â€™l2â€™, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None, \n",
    "# shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=None, learning_rate=â€™optimalâ€™, eta0=0.0, power_t=0.5, \n",
    "# class_weight=None, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "# some of methods\n",
    "# fit(X, y[, coef_init, intercept_init, â€¦])\tFit linear model with Stochastic Gradient Descent.\n",
    "# predict(X)\tPredict class labels for samples in X.\n",
    "\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(x_train_splited_model_1, y_train_splited_model_1)\n",
    "    predict_y = sig_clf.predict_proba(x_test_splited_model_1)\n",
    "    log_error_array.append(log_loss(y_test_splited_model_1, predict_y, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test_splited_model_1, predict_y, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Testing, Use whole training data and whole test data\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(x_train_model_1, y_train_model_1)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(x_train_model_1)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train_model_1, predict_y,eps=1e-15))\n",
    "y_predict_model_1 = sig_clf.predict_proba(x_test_model_1)\n",
    "y_predict_model_1_max =np.argmax(y_predict_model_1,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_1_max))\n",
    "# plot_confusion_matrix(y_test, predicted_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15420525, 0.52309526, 0.70979283, ..., 0.02388547, 0.73646388,\n",
       "       0.2878648 ])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_model_1_final = y_predict_model_1[:,1]\n",
    "y_predict_model_1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_model_1_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a submission for model\n",
    "\n",
    "df = pd.read_csv('Data/sample_submission.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_duplicate'] = y_predict_model_1_final\n",
    "df.to_csv('Models/qqp_linear_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized Method:\n",
    "- Model 1-1: To find the best parameter, i did lots of fine-tuning on alpha, the process are recorded on, only show the final results below. `scored:0.423`\n",
    "- Model 1-2: To find the best linear model, i did some experiments on parameters of SGDClassifier like penalty, loss, etc, the process are recorded on, not better than previous ones. `Scored:0.425`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Model 1\n",
    "# Preparation: apply scaling to train and test data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "x_train_model_1_1 = scale.fit_transform(x_train)\n",
    "x_test_model_1_1 = scale.transform(x_test)\n",
    "\n",
    "x_train_splited_model_1_1 = scale.fit_transform(x_train_splited)\n",
    "x_test_splited_model_1_1 = scale.transform(x_test_splited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of alpha =  0.00054 The log loss is: 0.4796416911909654\n",
      "For values of alpha =  0.00054 The log loss is: 0.4796416911909654\n",
      "For values of alpha =  0.00054 The log loss is: 0.4796416911909654\n",
      "For values of alpha =  0.00054 The log loss is: 0.4796416911909654\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00055 The log loss is: 0.47962879583799656\n",
      "For values of alpha =  0.00056 The log loss is: 0.47961686066166875\n",
      "For values of alpha =  0.00056 The log loss is: 0.47961686066166875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of best alpha =  0.00056 The train log loss is: 0.47979159467817944\n",
      "Total number of data points : 2345796\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "\n",
    "# prepare data for this model\n",
    "y_train_model_1_1 = y_train\n",
    "y_train_splited_model_1_1 = y_train_splited\n",
    "y_test_splited_model_1_1 = y_test_splited\n",
    "\n",
    "\n",
    "# Training, use prepared data to do the training.\n",
    "np.random.seed(25)\n",
    "alpha = np.random.uniform(0.00054 ,0.00056,20)   # 0.00055,0.00065\n",
    "alpha = np.round(alpha,5)\n",
    "alpha.sort()\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(x_train_splited_model_1_1, y_train_splited_model_1_1)\n",
    "    predict_y = sig_clf.predict_proba(x_test_splited_model_1_1)\n",
    "    log_error_array.append(log_loss(y_test_splited_model_1_1, predict_y,eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test_splited_model_1_1, predict_y,eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Testing: Use the best parameter to predict test data:\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(x_train_model_1_1, y_train_model_1_1)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(x_train_model_1_1)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train_model_1_1, predict_y,eps=1e-15))\n",
    "y_predict_model_1_1 = sig_clf.predict_proba(x_test_model_1_1)\n",
    "y_predict_model_1_1_max =np.argmax(y_predict_model_1_1,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_1_1_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "\n",
    "y_predict_model_1_1_final = y_predict_model_1_1[:,1]\n",
    "df = pd.read_csv('Data/sample_submission.csv')\n",
    "df['is_duplicate'] = y_predict_model_1_1_final\n",
    "df.to_csv('Models/qqp_linear_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Model 2, change the loss and the regularization type, this makes it SVM(right?)\n",
    "# Preparation: Apply scaling to train and test data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "x_train_model_1_2 = scale.fit_transform(x_train)\n",
    "x_test_model_1_2 = scale.transform(x_test)\n",
    "\n",
    "x_train_splited_model_1_2 = scale.fit_transform(x_train_splited)\n",
    "x_test_splited_model_1_2 = scale.transform(x_test_splited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of alpha =  0.00061 The log loss is: 0.4844390220552555\n",
      "For values of alpha =  0.00062 The log loss is: 0.4843559073443489\n",
      "For values of alpha =  0.00066 The log loss is: 0.4840140848484696\n",
      "For values of alpha =  0.00069 The log loss is: 0.4839310763760267\n",
      "For values of alpha =  0.00078 The log loss is: 0.48370262529556696\n",
      "For values of alpha =  0.00083 The log loss is: 0.4840309247827417\n",
      "For values of alpha =  0.00087 The log loss is: 0.48281264143389374\n",
      "For values of alpha =  0.00087 The log loss is: 0.48281264143389374\n",
      "For values of alpha =  0.0009 The log loss is: 0.482898786033406\n",
      "For values of alpha =  0.00091 The log loss is: 0.48283334973628517\n",
      "For values of alpha =  0.00094 The log loss is: 0.4823173684610036\n",
      "For values of alpha =  0.00095 The log loss is: 0.4822844024482512\n",
      "For values of alpha =  0.00102 The log loss is: 0.48264933414076744\n",
      "For values of alpha =  0.00106 The log loss is: 0.48268480941542\n",
      "For values of alpha =  0.00108 The log loss is: 0.48263226735754916\n",
      "For values of alpha =  0.00109 The log loss is: 0.4826316616184199\n",
      "For values of alpha =  0.00118 The log loss is: 0.4820357139895417\n",
      "For values of alpha =  0.0012 The log loss is: 0.4820077144721983\n",
      "For values of alpha =  0.00134 The log loss is: 0.48200050777878073\n",
      "For values of alpha =  0.00137 The log loss is: 0.48199894459462417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For values of best alpha =  0.00137 The train log loss is: 0.4826850291603913\n",
      "Total number of data points : 2345796\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing\n",
    "\n",
    "# Prepare data for the model\n",
    "y_train_model_1_2 = y_train\n",
    "y_train_splited_model_1_2 = y_train_splited\n",
    "y_test_splited_model_1_2 = y_test_splited\n",
    "\n",
    "\n",
    "# Training, use prepared data to train the model\n",
    "np.random.seed(25)\n",
    "alpha = np.random.uniform(0.0005 ,0.0015, 20)   # 0.00055,0.00065\n",
    "alpha = np.round(alpha,5)\n",
    "alpha.sort()\n",
    "log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(x_train_splited_model_1_2, y_train_splited_model_1_2)\n",
    "    predict_y = sig_clf.predict_proba(x_test_splited_model_1_2)\n",
    "    log_error_array.append(log_loss(y_test_splited_model_1_2, predict_y,eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_test_splited_model_1_2, predict_y,eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Testing, use the best parameter to predict test data:\n",
    "best_alpha = np.argmin(log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(x_train_model_1_2, y_train_model_1_2)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(x_train_model_1_2)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train_model_1_2, predict_y,eps=1e-15))\n",
    "y_predict_model_1_2 = sig_clf.predict_proba(x_test_model_1_2)\n",
    "y_predict_model_1_2_max =np.argmax(y_predict_model_1_2,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_1_2_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "y_predict_model_1_2_final = y_predict_model_1_2[:,1]\n",
    "df = pd.read_csv('Data/sample_submission.csv')\n",
    "df['is_duplicate'] = y_predict_model_1_2_final\n",
    "df.to_csv('Models/qqp_linear_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_2: Random Forest with Hyperparameter Tuning\n",
    "I plan to use rf model. `Scored 0.38007, 0.38000`\n",
    ">**ATTENTION! In fact, the 'Training and Testing' part can be seperated. The former for search the best parameter, and the latter for the model result based on the best para. That saves time for experiments.**\n",
    "\n",
    "> Okay, I will do it in the process of **CODE ORGANIZING** (PROCESS 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the model\n",
    "x_train_model_2 = x_train\n",
    "x_test_model_2 = x_test\n",
    "x_train_splited_model_2 = x_train_splited\n",
    "x_test_splited_model_2 = x_test_splited\n",
    "\n",
    "y_train_model_2 = y_train\n",
    "y_train_splited_model_2 = y_train_splited\n",
    "y_test_splited_model_2 = y_test_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimators =  100 Test Log Loss  0.39845190192282465\n",
      "estimators =  150 Test Log Loss  0.3975388218937196\n",
      "estimators =  200 Test Log Loss  0.3969507338734131\n",
      "estimators =  300 Test Log Loss  0.3962759199246605\n",
      "estimators =  400 Test Log Loss  0.39609464679778994\n",
      "estimators =  600 Test Log Loss  0.3959015279641766\n",
      "estimators =  800 Test Log Loss  0.3958018173663114\n",
      "For values of best estimator =  800 The train log loss is: 0.1145864894102081\n",
      "Total number of data points : 2345796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log Loss')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Testing \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "# Traning, using prepared data\n",
    "estimators = [100,150,200,300,400,600,800]\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in estimators:\n",
    "    # Model training\n",
    "    clf = RFC(n_estimators=i, random_state=32, n_jobs=-1) # n_job=-1 means using all processors\n",
    "    clf.fit(x_train_splited_model_2,y_train_splited_model_2ï¼‰\n",
    "    predict_y = clf.predict_proba(x_test_splited_model_2)\n",
    "    log_loss_test = log_loss(y_test_splited_model_2, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('estimators = ',i, 'Test Log Loss ',log_loss_test)\n",
    "\n",
    "# Testing, using the whole data set    \n",
    "best_estimator = np.argmin(test_scores) # return the index of the min value\n",
    "clf = RFC(n_estimators=estimators[best_estimator], random_state=32, n_jobs=-1)\n",
    "clf.fit(x_train_model_2, y_train_model_2)\n",
    "predict_y = clf.predict_proba(x_train_model_2)\n",
    "print('For values of best estimator = ', estimators[best_estimator], \"The train log loss is:\",\n",
    "      log_loss(y_train_model_2, predict_y,eps=1e-15))\n",
    "y_predict_model_2 = clf.predict_proba(x_test_model_2)\n",
    "y_predict_model_2_max =np.argmax(y_predict_model_2,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_2_max))\n",
    "\n",
    "# Visualization\n",
    "plt.plot(estimators,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('estimators')  \n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_model_2_final = y_predict_model_2[:,1]\n",
    "y_predict_model_2_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "# y_predict_model_1_2_final = y_predict_model_1_2[:,1]\n",
    "df = pd.read_csv('Data/sample_submission.csv')\n",
    "df['is_duplicate'] = y_predict_model_2_final\n",
    "df.to_csv('Models/qqp_rf_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40236793495520445"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see if the loss is smaller at 1000 \n",
    "# (i.e., the curve is still monotonically decreasing), but I won't increase n_estimators any more  \n",
    "clf_temp = RFC(n_estimators=1000, random_state=32, n_jobs=-1) # n_job=-1 means using all processors\n",
    "clf_temp.fit(x_train_splited_model_2,y_train_splited_model_2)\n",
    "# predict_y = clf.predict_proba(x_train_splited_model_2)\n",
    "# log_loss_train = log_loss(y_train_splited_model_2, predict_y, eps=1e-15)\n",
    "# train_scores.append(log_loss_train)\n",
    "predict_y = clf_temp.predict_proba(x_test_splited_model_2)\n",
    "temp = log_loss(y_test_splited_model_2, predict_y, eps=1e-15)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actually it's better, now i plan to use 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized Method:\n",
    "- Model 2-1: try depth fine tuning\n",
    "- Model 2-2: combine the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Model 2-1: try depth fine tuning\n",
    "# Prepare data for the model\n",
    "x_train_model_2_1 = x_train\n",
    "x_test_model_2_1 = x_test\n",
    "x_train_splited_model_2_1 = x_train_splited\n",
    "x_test_splited_model_2_1 = x_test_splited\n",
    "\n",
    "y_train_model_2_1 = y_train\n",
    "y_train_splited_model_2_1 = y_train_splited\n",
    "y_test_splited_model_2_1 = y_test_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth =  50 Test Log Loss  0.3958598896836761\n",
      "Depth =  65 Test Log Loss  0.39579212619392773\n",
      "Depth =  80 Test Log Loss  0.3958018173663114\n",
      "Depth =  100 Test Log Loss  0.3958018173663114\n",
      "best depth is: 65\n",
      "For values of best depth =  65 The train log loss is: 0.1145743585123209\n",
      "Total number of data points : 2345796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log Loss')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Testing \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "# Traning, using prepared data\n",
    "# Depth = [5,10,12,15,20,25,50]\n",
    "Depth = [50, 65, 80, 100]\n",
    "# Depth = \n",
    "test_scores = []\n",
    "train_scores = []\n",
    "for i in Depth:\n",
    "    # Model training, using the best estimators.\n",
    "    clf = RFC(n_estimators=800, max_depth=i, random_state=32, n_jobs=-1) # n_job=-1 means using all processors\n",
    "    clf.fit(x_train_splited_model_2_1,y_train_splited_model_2_1)\n",
    "    \n",
    "    predict_y = clf.predict_proba(x_test_splited_model_2_1)\n",
    "    log_loss_test = log_loss(y_test_splited_model_2_1, predict_y, eps=1e-15)\n",
    "    test_scores.append(log_loss_test)\n",
    "    print('Depth = ',i, 'Test Log Loss ',log_loss_test)\n",
    "\n",
    "# Testing, using the whole data set    \n",
    "best_depth = np.argmin(test_scores) # return the index of the min value\n",
    "print('best depth is:', Depth[best_depth])\n",
    "clf = RFC(n_estimators=800, max_depth=Depth[best_depth], random_state=32, n_jobs=-1)\n",
    "clf.fit(x_train_model_2_1, y_train_model_2_1)\n",
    "predict_y = clf.predict_proba(x_train_model_2_1)\n",
    "print('For values of best depth = ', Depth[best_depth], \"The train log loss is:\",log_loss(y_train_model_2_1, predict_y,eps=1e-15))\n",
    "y_predict_model_2_1 = clf.predict_proba(x_test_model_2_1)\n",
    "y_predict_model_2_1_max =np.argmax(y_predict_model_2_1,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_2_1_max))\n",
    "\n",
    "# Visualization\n",
    "plt.plot(Depth,test_scores,label='Test Log Loss')\n",
    "plt.xlabel('Depth')  \n",
    "plt.ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the 2nd iteration, i only use parameter{n_estimators=800, depth=65} for 2nd features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth is: 65\n",
      "For values of best depth =  65 The train log loss is: 0.11456674055245297\n",
      "Total number of data points : 2345796\n"
     ]
    }
   ],
   "source": [
    "# Testing, using the whole data set    \n",
    "# best_depth = np.argmin(test_scores) # return the index of the min value\n",
    "\n",
    "print('best depth is:', Depth[best_depth])\n",
    "clf = RFC(n_estimators=1000, max_depth=65, random_state=32, n_jobs=-1)\n",
    "clf.fit(x_train_model_2_1, y_train_model_2_1)\n",
    "predict_y = clf.predict_proba(x_train_model_2_1)\n",
    "print('For values of best depth = ', Depth[best_depth], \"The train log loss is:\",log_loss(y_train_model_2_1, predict_y,eps=1e-15))\n",
    "y_predict_model_2_1 = clf.predict_proba(x_test_model_2_1)\n",
    "y_predict_model_2_1_max =np.argmax(y_predict_model_2_1,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_2_1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "\n",
    "y_predict_model_2_1_final = y_predict_model_2_1[:,1]\n",
    "df = pd.read_csv('Data/sample_submission.csv')\n",
    "df['is_duplicate'] = y_predict_model_2_1_final\n",
    "df.to_csv('Models/qqp_rf_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_3: XGBoost with Hyperparameter Tuning\n",
    "I plan to use xgb model. But my param_dist is just narrow, maybe my teamates can do some parameter fine-tuning for me. `Scored: 0.34376` on xgb_3, currently best model.\n",
    "\n",
    "- parameter fine tuning refers to: https://blog.csdn.net/u010657489/article/details/51952785, https://www.cnblogs.com/TimVerion/p/11436001.html, https://baijiahao.baidu.com/s?id=1613550753243799306&wfr=spider&for=pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the model\n",
    "x_train_model_3 = x_train\n",
    "x_test_model_3 = x_test\n",
    "# x_train_splited_model_3 = x_train_splited\n",
    "# x_test_splited_model_3 = x_test_splited\n",
    "\n",
    "y_train_model_3 = y_train\n",
    "# y_train_splited_model_3 = y_train_splited\n",
    "# y_test_splited_model_3 = y_test_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingï¼š nearly 3h to dump process 20min dump\n",
    "\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle\n",
    "\n",
    "param_dist = {\"n_estimators\":randint(300,600),\n",
    "              \"learning_rate\":uniform(0,0.1),\n",
    "              \"max_depth\":randint(4,16),\n",
    "              \"gamma\":uniform(0,4),\n",
    "              \"subsample\":uniform(0.7,0.3),\n",
    "              \"colsample_bytree\": uniform(0.7,0.3),\n",
    "              \"min_child_weight\": randint(2, 8),\n",
    "              \"reg_alpha\":uniform(100,300),\n",
    "              \"reg_lambda\":uniform(100,300)}\n",
    "\n",
    "xgbclf = RandomizedSearchCV(xgb.XGBClassifier(random_state=25, n_jobs=-1), param_distributions=param_dist,\n",
    "                                   n_iter=10,scoring='neg_log_loss',cv=5,n_jobs=-1)\n",
    "xgbclf.fit(x_train_model_3, y_train_model_3)\n",
    "\n",
    "# store the model\n",
    "pickle.dump(xgbclf,open('Models/model_xgbclf_4.p','wb'))\n",
    "\n",
    "# n_iter=10, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8907752073656516,\n",
       "              gamma=2.4729845565448296, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.06563379348627883,\n",
       "              max_delta_step=0, max_depth=8, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=582, n_jobs=-1,\n",
       "              num_parallel_tree=1, objective='binary:logistic', random_state=25,\n",
       "              reg_alpha=123.14676313765456, reg_lambda=167.05141370916164,\n",
       "              scale_pos_weight=1, subsample=0.77368152051838,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8907752073656516,\n",
       " 'gamma': 2.4729845565448296,\n",
       " 'learning_rate': 0.06563379348627883,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 582,\n",
       " 'reg_alpha': 123.14676313765456,\n",
       " 'reg_lambda': 167.05141370916164,\n",
       " 'subsample': 0.77368152051838}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37418917581723427"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6358.96234703064"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf.refit_time_  # running time: around half an hour, the average time is 40min/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_dict = xgbclf.cv_results_  # dictionary type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([13876.04859042, 17283.26502156, 18137.35828924, 27929.8087574 ,\n",
       "        23197.10313406, 11307.30073338, 13936.06409063, 50496.0764904 ,\n",
       "        44088.56073585, 20475.93408155]),\n",
       " 'std_fit_time': array([2.23196965e+01, 7.70159481e+00, 7.48281244e+01, 9.68518147e+01,\n",
       "        1.56640097e+03, 1.53757897e+03, 2.42763187e+01, 2.31303334e+03,\n",
       "        3.15510866e+02, 1.39412958e+04]),\n",
       " 'mean_score_time': array([ 7.72842727,  7.73247561, 10.00022535, 24.85160565, 14.32154403,\n",
       "         5.94600801,  6.02669239, 13.62627063,  9.86720681,  7.52166696]),\n",
       " 'std_score_time': array([0.20176414, 0.29866662, 0.688039  , 0.97489443, 0.97865075,\n",
       "        0.45665529, 0.29715479, 5.73534871, 1.68058318, 4.31987897]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.8337929281084345, 0.9694738338103441,\n",
       "                    0.8378884294296214, 0.8462777019992609,\n",
       "                    0.8907752073656516, 0.700051970645461,\n",
       "                    0.8816259025246378, 0.9384802916285753,\n",
       "                    0.8780867099545138, 0.7461899433791453],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[3.2419820903023164, 2.4253730971208154,\n",
       "                    0.33660980573041543, 0.11284177040421683,\n",
       "                    2.4729845565448296, 3.7469839182173166,\n",
       "                    1.3789701477033214, 3.41496315191102,\n",
       "                    1.8231787734907097, 1.5463135063508027],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.07561301843948348, 0.068353208642838,\n",
       "                    0.031054792639694753, 0.026964874403452178,\n",
       "                    0.06563379348627883, 0.07354626267282605,\n",
       "                    0.06026965257672863, 0.07541731916761099,\n",
       "                    0.08047643323245389, 0.06981601946175219],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[8, 7, 8, 13, 8, 7, 5, 15, 14, 11],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[7, 3, 2, 3, 3, 2, 4, 3, 5, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[383, 481, 484, 528, 582, 351, 441, 493, 503, 548],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[109.5635988245613, 281.41116291230855,\n",
       "                    214.0196102526008, 265.4715140257531,\n",
       "                    123.14676313765456, 306.6521825007668,\n",
       "                    331.1661919179518, 209.52982197425015,\n",
       "                    294.9212020793172, 376.93711881100853],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_lambda': masked_array(data=[205.75726587786056, 116.80357918075262,\n",
       "                    289.1204938806975, 253.91743744746157,\n",
       "                    167.05141370916164, 217.3342395528479,\n",
       "                    358.729587821352, 316.46247344985136,\n",
       "                    241.51447219478524, 163.93386654515638],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.8080845435090759, 0.8436448055028878,\n",
       "                    0.8969900312351361, 0.7186548914814523,\n",
       "                    0.77368152051838, 0.8031537300383185,\n",
       "                    0.7633446706867248, 0.779691943612487,\n",
       "                    0.8098612826041391, 0.8459258166613504],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.8337929281084345,\n",
       "   'gamma': 3.2419820903023164,\n",
       "   'learning_rate': 0.07561301843948348,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 7,\n",
       "   'n_estimators': 383,\n",
       "   'reg_alpha': 109.5635988245613,\n",
       "   'reg_lambda': 205.75726587786056,\n",
       "   'subsample': 0.8080845435090759},\n",
       "  {'colsample_bytree': 0.9694738338103441,\n",
       "   'gamma': 2.4253730971208154,\n",
       "   'learning_rate': 0.068353208642838,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 481,\n",
       "   'reg_alpha': 281.41116291230855,\n",
       "   'reg_lambda': 116.80357918075262,\n",
       "   'subsample': 0.8436448055028878},\n",
       "  {'colsample_bytree': 0.8378884294296214,\n",
       "   'gamma': 0.33660980573041543,\n",
       "   'learning_rate': 0.031054792639694753,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 2,\n",
       "   'n_estimators': 484,\n",
       "   'reg_alpha': 214.0196102526008,\n",
       "   'reg_lambda': 289.1204938806975,\n",
       "   'subsample': 0.8969900312351361},\n",
       "  {'colsample_bytree': 0.8462777019992609,\n",
       "   'gamma': 0.11284177040421683,\n",
       "   'learning_rate': 0.026964874403452178,\n",
       "   'max_depth': 13,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 528,\n",
       "   'reg_alpha': 265.4715140257531,\n",
       "   'reg_lambda': 253.91743744746157,\n",
       "   'subsample': 0.7186548914814523},\n",
       "  {'colsample_bytree': 0.8907752073656516,\n",
       "   'gamma': 2.4729845565448296,\n",
       "   'learning_rate': 0.06563379348627883,\n",
       "   'max_depth': 8,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 582,\n",
       "   'reg_alpha': 123.14676313765456,\n",
       "   'reg_lambda': 167.05141370916164,\n",
       "   'subsample': 0.77368152051838},\n",
       "  {'colsample_bytree': 0.700051970645461,\n",
       "   'gamma': 3.7469839182173166,\n",
       "   'learning_rate': 0.07354626267282605,\n",
       "   'max_depth': 7,\n",
       "   'min_child_weight': 2,\n",
       "   'n_estimators': 351,\n",
       "   'reg_alpha': 306.6521825007668,\n",
       "   'reg_lambda': 217.3342395528479,\n",
       "   'subsample': 0.8031537300383185},\n",
       "  {'colsample_bytree': 0.8816259025246378,\n",
       "   'gamma': 1.3789701477033214,\n",
       "   'learning_rate': 0.06026965257672863,\n",
       "   'max_depth': 5,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 441,\n",
       "   'reg_alpha': 331.1661919179518,\n",
       "   'reg_lambda': 358.729587821352,\n",
       "   'subsample': 0.7633446706867248},\n",
       "  {'colsample_bytree': 0.9384802916285753,\n",
       "   'gamma': 3.41496315191102,\n",
       "   'learning_rate': 0.07541731916761099,\n",
       "   'max_depth': 15,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 493,\n",
       "   'reg_alpha': 209.52982197425015,\n",
       "   'reg_lambda': 316.46247344985136,\n",
       "   'subsample': 0.779691943612487},\n",
       "  {'colsample_bytree': 0.8780867099545138,\n",
       "   'gamma': 1.8231787734907097,\n",
       "   'learning_rate': 0.08047643323245389,\n",
       "   'max_depth': 14,\n",
       "   'min_child_weight': 5,\n",
       "   'n_estimators': 503,\n",
       "   'reg_alpha': 294.9212020793172,\n",
       "   'reg_lambda': 241.51447219478524,\n",
       "   'subsample': 0.8098612826041391},\n",
       "  {'colsample_bytree': 0.7461899433791453,\n",
       "   'gamma': 1.5463135063508027,\n",
       "   'learning_rate': 0.06981601946175219,\n",
       "   'max_depth': 11,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 548,\n",
       "   'reg_alpha': 376.93711881100853,\n",
       "   'reg_lambda': 163.93386654515638,\n",
       "   'subsample': 0.8459258166613504}],\n",
       " 'split0_test_score': array([-0.3802344 , -0.39356707, -0.40188653, -0.40326059, -0.37512966,\n",
       "        -0.40231824, -0.41172557, -0.38091538, -0.38462589, -0.39320903]),\n",
       " 'split1_test_score': array([-0.37885274, -0.39163952, -0.3996794 , -0.4011153 , -0.37309121,\n",
       "        -0.40003406, -0.40893067, -0.37878976, -0.38220145, -0.39092256]),\n",
       " 'split2_test_score': array([-0.38124197, -0.39366852, -0.40220318, -0.403603  , -0.37569765,\n",
       "        -0.40280407, -0.41146425, -0.38129311, -0.38493954, -0.39426055]),\n",
       " 'split3_test_score': array([-0.37834481, -0.39160385, -0.39989124, -0.40144614, -0.37377373,\n",
       "        -0.40022905, -0.40934261, -0.3793977 , -0.38275192, -0.39105107]),\n",
       " 'split4_test_score': array([-0.37873331, -0.39188476, -0.40007408, -0.40155769, -0.37325362,\n",
       "        -0.40074631, -0.40992127, -0.3788543 , -0.38263975, -0.39138989]),\n",
       " 'mean_test_score': array([-0.37948145, -0.39247275, -0.40074689, -0.40219655, -0.37418918,\n",
       "        -0.40122635, -0.41027687, -0.37985005, -0.38343171, -0.39216662]),\n",
       " 'std_test_score': array([0.0010875 , 0.00094047, 0.00107182, 0.00102476, 0.00104052,\n",
       "        0.00112499, 0.0011243 , 0.0010524 , 0.00112272, 0.00133166]),\n",
       " 'rank_test_score': array([ 2,  6,  7,  9,  1,  8, 10,  3,  4,  5], dtype=int32)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>582</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>8</td>\n",
       "      <td>2.472985</td>\n",
       "      <td>0.773682</td>\n",
       "      <td>0.890775</td>\n",
       "      <td>3</td>\n",
       "      <td>123.146763</td>\n",
       "      <td>167.051414</td>\n",
       "      <td>-0.374189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>0.075613</td>\n",
       "      <td>8</td>\n",
       "      <td>3.241982</td>\n",
       "      <td>0.808085</td>\n",
       "      <td>0.833793</td>\n",
       "      <td>7</td>\n",
       "      <td>109.563599</td>\n",
       "      <td>205.757266</td>\n",
       "      <td>-0.379481</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>493</td>\n",
       "      <td>0.075417</td>\n",
       "      <td>15</td>\n",
       "      <td>3.414963</td>\n",
       "      <td>0.779692</td>\n",
       "      <td>0.938480</td>\n",
       "      <td>3</td>\n",
       "      <td>209.529822</td>\n",
       "      <td>316.462473</td>\n",
       "      <td>-0.379850</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>503</td>\n",
       "      <td>0.080476</td>\n",
       "      <td>14</td>\n",
       "      <td>1.823179</td>\n",
       "      <td>0.809861</td>\n",
       "      <td>0.878087</td>\n",
       "      <td>5</td>\n",
       "      <td>294.921202</td>\n",
       "      <td>241.514472</td>\n",
       "      <td>-0.383432</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>548</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>11</td>\n",
       "      <td>1.546314</td>\n",
       "      <td>0.845926</td>\n",
       "      <td>0.746190</td>\n",
       "      <td>4</td>\n",
       "      <td>376.937119</td>\n",
       "      <td>163.933867</td>\n",
       "      <td>-0.392167</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>0.068353</td>\n",
       "      <td>7</td>\n",
       "      <td>2.425373</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.969474</td>\n",
       "      <td>3</td>\n",
       "      <td>281.411163</td>\n",
       "      <td>116.803579</td>\n",
       "      <td>-0.392473</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>0.031055</td>\n",
       "      <td>8</td>\n",
       "      <td>0.336610</td>\n",
       "      <td>0.896990</td>\n",
       "      <td>0.837888</td>\n",
       "      <td>2</td>\n",
       "      <td>214.019610</td>\n",
       "      <td>289.120494</td>\n",
       "      <td>-0.400747</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>351</td>\n",
       "      <td>0.073546</td>\n",
       "      <td>7</td>\n",
       "      <td>3.746984</td>\n",
       "      <td>0.803154</td>\n",
       "      <td>0.700052</td>\n",
       "      <td>2</td>\n",
       "      <td>306.652183</td>\n",
       "      <td>217.334240</td>\n",
       "      <td>-0.401226</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>528</td>\n",
       "      <td>0.026965</td>\n",
       "      <td>13</td>\n",
       "      <td>0.112842</td>\n",
       "      <td>0.718655</td>\n",
       "      <td>0.846278</td>\n",
       "      <td>3</td>\n",
       "      <td>265.471514</td>\n",
       "      <td>253.917437</td>\n",
       "      <td>-0.402197</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>441</td>\n",
       "      <td>0.060270</td>\n",
       "      <td>5</td>\n",
       "      <td>1.378970</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.881626</td>\n",
       "      <td>4</td>\n",
       "      <td>331.166192</td>\n",
       "      <td>358.729588</td>\n",
       "      <td>-0.410277</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  learning_rate  max_depth     gamma  subsample  \\\n",
       "4           582       0.065634          8  2.472985   0.773682   \n",
       "0           383       0.075613          8  3.241982   0.808085   \n",
       "7           493       0.075417         15  3.414963   0.779692   \n",
       "8           503       0.080476         14  1.823179   0.809861   \n",
       "9           548       0.069816         11  1.546314   0.845926   \n",
       "1           481       0.068353          7  2.425373   0.843645   \n",
       "2           484       0.031055          8  0.336610   0.896990   \n",
       "5           351       0.073546          7  3.746984   0.803154   \n",
       "3           528       0.026965         13  0.112842   0.718655   \n",
       "6           441       0.060270          5  1.378970   0.763345   \n",
       "\n",
       "   colsample_bytree  min_child_weight   reg_alpha  reg_lambda  \\\n",
       "4          0.890775                 3  123.146763  167.051414   \n",
       "0          0.833793                 7  109.563599  205.757266   \n",
       "7          0.938480                 3  209.529822  316.462473   \n",
       "8          0.878087                 5  294.921202  241.514472   \n",
       "9          0.746190                 4  376.937119  163.933867   \n",
       "1          0.969474                 3  281.411163  116.803579   \n",
       "2          0.837888                 2  214.019610  289.120494   \n",
       "5          0.700052                 2  306.652183  217.334240   \n",
       "3          0.846278                 3  265.471514  253.917437   \n",
       "6          0.881626                 4  331.166192  358.729588   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "4        -0.374189                1  \n",
       "0        -0.379481                2  \n",
       "7        -0.379850                3  \n",
       "8        -0.383432                4  \n",
       "9        -0.392167                5  \n",
       "1        -0.392473                6  \n",
       "2        -0.400747                7  \n",
       "5        -0.401226                8  \n",
       "3        -0.402197                9  \n",
       "6        -0.410277               10  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best parameters\n",
    "\n",
    "# gather them to a dataframe for visualization\n",
    "result_list = []  # record all parameters and scores in n_iters\n",
    "for item in result_dict['params']:\n",
    "    para_list = []\n",
    "    para_list.append(item['n_estimators'])\n",
    "    para_list.append(item['learning_rate'])\n",
    "    para_list.append(item['max_depth'])\n",
    "    para_list.append(item['gamma'])\n",
    "    para_list.append(item['subsample'])\n",
    "    para_list.append(item['colsample_bytree'])\n",
    "    para_list.append(item['min_child_weight'])\n",
    "    para_list.append(item['reg_alpha'])\n",
    "    para_list.append(item['reg_lambda'])\n",
    "    result_list.append(para_list)\n",
    "result_list_df = pd.DataFrame(result_list,columns=['n_estimators','learning_rate','max_depth','gamma','subsample','colsample_bytree','min_child_weight','reg_alpha','reg_lambda'])\n",
    "    \n",
    "result_list_df['mean_test_score'] = result_dict['mean_test_score']\n",
    "result_list_df['rank_test_score'] = result_dict['rank_test_score']\n",
    "\n",
    "result_list_df.sort_values('rank_test_score').head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the best score after some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See the results\n",
    "\n",
    "import pickle\n",
    "\n",
    "# load data from pickle file\n",
    "f = open('Models/model_xgbclf_3.p','rb')\n",
    "xgbclf_result = pickle.load(f)\n",
    "xgbclf = xgbclf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points : 2345796\n"
     ]
    }
   ],
   "source": [
    "# Tesing: get the best estimator and predict the test data 11.29\n",
    "\n",
    "xgbclf_final = xgbclf.best_estimator_\n",
    "xgbclf_final.fit(x_train_model_3, y_train_model_3)\n",
    "y_predict_model_3 = xgbclf_final.predict_proba(x_test_model_3)\n",
    "y_predict_model_3_max =np.argmax(y_predict_model_3,axis=1)\n",
    "print(\"Total number of data points :\", len(y_predict_model_3_max))\n",
    "# plot_confusion_matrix(y_test, predicted_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission\n",
    "\n",
    "y_predict_model_3_final = y_predict_model_3[:,1]\n",
    "df = pd.read_csv('Data/sample_submission.csv')\n",
    "df['is_duplicate'] = y_predict_model_3_final\n",
    "df.to_csv('Models/qqp_xgb_temp.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_4: Siamese LSTM\n",
    "\n",
    "- This part has been moved to files like `lstm.ipynb`, `bilstm.ipynb`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "204px",
    "width": "444px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
